@incollection{Itti02cnca,
author = { L. Itti },
title = { Modeling Primate Visual Attention },
year = {in press},
booktitle = { Computational Neuroscience: A Comprehensive Approach },
publisher = {CRC Press},
address={Boca Raton},
abstract={Selective visual attention is the mechanism by which we can
rapidly direct our gaze towards objects of interest in our visual
environment.  From an evolutionary viewpoint, this rapid orienting
capability is critical in allowing living systems to quickly become
aware of possible preys, mates or predators in their cluttered visual
world.  It has become clear that attention guides where to look next
based on both bottom-up (image-based) and top-down (task-dependent)
cues.  As such, attention implements an information processing
bottleneck, only allowing a small part of the incoming sensory
information to reach short-term memory and visual awareness.  That is,
instead of attempting to fully process the massive sensory input in
parallel, nature has devised a serial strategy to achieve near
real-time performance despite limited computational capacity:
Attention allows us to break down the problem of scene understanding
into rapid series of computationally less demanding, localized visual
analysis problems.  These orienting and scene analysis functions of
attention are complemented by a feedback modulation of neural activity
at the location and for the visual attributes of the desired or
selected targets. This feedback is believed to be essential for
binding the different visual attributes of an object, such as color
and form, into a unitary percept. That is, attention not only serves
to select a location of interest, but also enhances the cortical
representation at that location. As such, focal visual attention is
often compared to a rapidly shiftable spotlight, which scans our
visual environment both overtly (with accompanying eye movements) or
covertly (with the eyes fixed).  Finally, attention is involved in
triggering behavior, and consequently is intimately related to
recognition, planning and motor control. Of course, not all of vision
is attentional, as we can derive coarse understanding from
presentations of visual scenes that are too brief for attention to
explore the scene. Vision thus relies on sophisticated interactions
between coarse, massively parallel, full-field pre-attentive analysis
systems and the more detailed, circumscribed and sequential
attentional analysis system.  In what follows, we focus on several
critical aspects of selective visual attention: First, the brain area
involved in its control and deployment; second, the mechanisms by
which attention is attracted in a bottom-up or image-based manner
towards conspicuous or salient locations in our visual environment;
third, the mechanisms by which attention modulates the early sensory
representation of attended stimuli; fourth, the mechanisms for
top-down or voluntary deployment of attention; and fifth, the
interaction between attention, object recognition and scene
understanding.  },
editor = {J. Feng},
file = { http://iLab.usc.edu/publications/doc/Itti02cnca.pdf },
type={mod|bu|td|psy|rev|sc}
}

@article{Itti_etal02jnm,
author={E. Itti and I. T. G. Gonzalo and L. Itti and F. S. Mishkin
and R. S. Swerdloff},
title={Brain perfusion mapping shows ``inverse'' hemispheric dominance in 
men with Klinefelter syndrome},
year={2002},
month={May},
journal={Journal of Nuclear Medicine},
volume={43},
number={5},
pages={S1026},
type={med}
}

@inproceedings{Navalpakkam_Itti02jsnc,
author={V. Navalpakkam and L. Itti},
title={A Biologically-Inspired Scene-based Question Answering Agent},
abstract={},
booktitle={Proc. 9th Joint Symposium on Neural Computation (JSNC'02),
Pasadena, California},
year={2002},
month={May},
type={mod|bu|sc},
file = { http://iLab.usc.edu/publications/doc/Navalpakkam_Itti02jsnc.pdf }
}

@inproceedings{Chung_Itti02jsnc,
author={D. Chung and L. Itti},
title={Object recognition in the early visual system},
abstract={To complement our previous modeling of visual attention and
the 'where' processing stream in the primate brain, we now investigate
the recognition of objects at the attended locations in the 'what'
visual processing stream. In the work we built an object recognition
system of view-tuned units (16 × 16 pixels, 8-bit gray level
scale). The view-tuned units are believed as a critical part for
object recognition of human brain, which is found in the
inferotemporal cortex. The view-tuned units are constructed using HMAX
model that was proposed by M. Reisenhuber and T. Poggio (Hierarchical
models of object recognition in cortex. Nat Neurosci, 2:1019-1025,
1999). HMAX was based on the hierarchical model of early visual system
that uses some amount of abstraction from the incoming information to
primary visual system. In our implementation of HMAX, the input image
(128 × 128 pixels) is contracted into 16 × 16 pixels view-tuned
units. As the result, the view-tuned units can be said not only to
possess the information of the image, but also some degree of
invariance to scale and translation. Here we tested with three types
of polygons for the classification(or recognition) problem,
i.e. ellipses, rectangles, and triangles with several variations of
orientations, positions, shapes, sizes, and even occlusions. With two
different approaches, we implemented the successful classification
solutions for the view-tuned units. One method was a simple linear
method, which is mentioned in the paper by Reisenhuber and Poggio. The
point for this work was on the comparison of the simple linear method
with a more sophisticated and expensive method, Support Vector
Machine. We tested for the improvement in the performance of the
trained classifiers. We used three different kernels for the SVM: dot
product (linear), degree 2 polynomial, and Radial Basis Function. At
the results, both the linear method and the SVM-based methods used in
this project constructed adequate classifiers for the classification
of simple grayscale level images. In fact when we used expensive
methods of classification such as SVM with linear and polynomial
kernel, the model gave slightly worse results compared to the one with
simple linear method. From the experiments, we conclude that the
preprocessing (HMAX) already provide a clue for linear separation of
the data, thus the improvements by more sophisticated methods are
insignificant. Further experiments will extend this analysis to a
large number of objects, such as the natural environments with complex
situation, so the SVM classifier may prove more robust than the simple
linear classifier.},
booktitle={Proc. 9th Joint Symposium on Neural Computation (JSNC'02),
Pasadena, California},
year={2002},
month={May},
type={mod|bu|cv},
file = { http://iLab.usc.edu/publications/doc/Chung_Itti02jsnc.pdf }
}

@inproceedings{Ng_etal02jsnc,
author={J. Ng and R. Hirata and N. Mundhenk and E. Pichon and A. Tsui
and T. Ventrice and P. Williams and L. Itti},
title={Towards Visually-Guided Neuromorphic Robots: Beobots},
abstract={Despite the advancements made in the field of AI and
Robotics, robots today remain vastly inferior to animals in terms of
mental agility. The main reason for this is that robots do not possess
the neural capabilities of an animal brain. Neural algorithms adapt
well to diverse environments, whereas robot AI is usually limited to a
test lab setting. To resolve this disparity, an intuitive solution
would be to try to emulate the neural functions present in animal
brains. However, neural algorithms require vast amounts of
computational power to process, in particular those algorithms that
require real-time vision. Many robots, which run on power-saving
embedded processors, do not have a lot of CPU cycles to spare. We are
developing a high-performance visually-guided robotics platform with
enough processing speed to run neural algorithms. This 'Beobot'
platform consists of a high-performance radio-controlled truck chassis
(the robot) carrying an x86-based supercomputer (the Beowulf
cluster). The computing cluster consists of two compact dual-CPU
motherboards linked together by a gigabit Ethernet
connection. Powering the computer are four Pentium-III (Coppermine)
1Ghz processors along with 768MB of memory per motherboard. Two
Firewire cameras provide the Beobot's vision. A compact flash card is
used as a makeshift hard drive, and it has enough space to store a
thin UNIX-variant kernel and iLab's vision software. The vision
software itself consists of several general-purpose neural
algorithms. Most prominent of these is iLab's Saliency-based visual
attention system, which enables the Beobot to drive its attention
towards the most salient locations and objects in a visual scene. In
addition, we have developed prototype algorithms that allow the Beobot
to parse scene layouts and perform object recognition. A primitive
action/memory AI system allows it to implement simple visually-guided
behavior. Finally, the component-oriented nature of the vision
software enables future additions of neural modules. The potential
advantage of the Beobot comes from its use of x86-based hardware and
UNIX-based C++ development environment. Nearly all the parts of the
Beobot are inexpensive, off-the-shelf components. This enables easy
replacement of broken parts. Furthermore, the expandability of PC
hardware enables devices to be plugged into the Beobot for additional
functionalities. All these traits combined make the Beobot potentially
easy to replicate, and this allows for wider adoption upon the
successful completion of the prototype.},
booktitle={Proc. 9th Joint Symposium on Neural Computation (JSNC'02),
Pasadena, California},
year={2002},
month={May},
type={mod|bu|cv|bb},
file = { http://iLab.usc.edu/publications/doc/Ng_etal02jsnc.pdf }
}

@inproceedings{Mundhenk_Itti02jsnc,
author={T. N. Mundhenk and L. Itti},
title={Towards a simpler model of contour integration in early visual
processing using a composite of methods},
abstract={iLab has been attempting to simulate contour integration in
early visual preprocessing. Our model starts with a standard butterfly
pattern of neural connections that excite or suppress neighboring
neurons depending on their preferred visual orientation used for
instance by Li (1998). This creates systems where neurons tend to
excite other neurons with a collinear orientation, but tend to
suppress neurons with a parallel orientation. Our current model
attempts to distance itself from many current models that use either
neuro synchronization or cascade effect to obtain good contour
detection. Instead, we have concentrated on a simpler composite model
that uses group suppression gain control, multi scale image analysis
and fast plasticity. In this, group suppression works by summing the
excitation for small groups of neurons. If the group exceeds
threshold, proportionately suppression among the group s neurons is
increased. Fast plasticity works by increasing the excitatory ability
of a neuron if it has been excited by neighboring neurons to a large
enough extent. Finally, multi scale processing works by taking the
result of processing the same image in multiple scales on the same
neural kernel model at each scale. Experiments on real world images
shows that contours are most noticeably improved by the use of group
suppression gain control, while tests on computer generated contours
provided by Jachen Braun that are of varying size, phase and alignment
shows improvement most from the use of fast plasticity and multi scale
processing. Our results so far suggest that all three additions a both
viable and helpful. Further, our model suggests that simpler
mechanisms can be used by the brain in the act of early visual contour
integration. },
booktitle={Proc. 9th Joint Symposium on Neural Computation (JSNC'02),
Pasadena, California},
year={2002},
month={May},
type={mod|bu},
file = { http://iLab.usc.edu/publications/doc/Mundhenk_Itti02jsnc.pdf }
}

@article{Itti_etal02cnm,
author={E. Itti and K. Huff and M. E. Cornford and L. Itti and K. Poruri
and F. S. Mishkin},
title={Postinfectious encephalitis - A coregistered SPECT and magnetic 
resonance imaging study},
journal={Clinical Nuclear Medicine},
volume={27},
number={2},
year={2002},
month={Feb},
pages={129-130},
type={med}
}


@inproceedings{Mundhenk_Itti02cns,
author={T. N. Mundhenk and L. Itti},
title={CINNIC, a new computational algorithm for the modeling of early 
visual contour integration in humans},
abstract={We have developed a computational model called CINNIC to
simulate contour integration and visual salience in early visual
processing in the human brain. Our model uses the standard butterfly
pattern of connections between early orientation selective neurons,
which are believed to mediate interactions along contour
elements. However, we add multi scale analysis, adaptive neuron group
suppression and fast plasticity of connection weights to increase the
performance of our algorithm. We show quantitatively that the addition
of these ideas helps in the detection of salient contours. We also
submit that our algorithm is biologically plausible and falls in line
with what is known about neuron connections and interactions in V1 and
possibly V2. },
booktitle={Proc. Annual Computational Neuroscience Meeting (CNS*2002),
Chicago, Illinois},
year={in press},
type={mod|bu},
file = { http://iLab.usc.edu/publications/doc/Mundhenk_Itti02cns.pdf }
}

@inproceedings{Walther_etal02cns,
author = { D. Walther and M. Riesenhuber and T. Poggio and L. Itti and
C. Koch },
title = { Towards an integrated model of saliency-based attention and
object recognition in the primate's visual system },
year                = {in press},
abstract = {We present an integrated model for the dorsal (where) and
the ventral (what) pathway in the primate's visual processing system
and the interaction between these two pathways. To reach our goal of
modeling visual search behavior in primates, we integrate and extend
the saliency-based model for bottom-up attention by Itti and Koch
(Nat. Rev. Neurosci. 2001;2(3):194-203) and the HMAX hierarchical
model for object recognition by Riesenhuber and Poggio
(Nat. Neurosci. 1999;2:1019-1025).  In the combined model we use
saliency-based attention to modulate object recognition at the V4
level.  Interesting regions in the visual scene are successively
selected by a rapidly shiftable focus of attention (FOA).  Neural
activity of a particular neuron in V4 is inhibited based on its
distance from the current FOA.  Recognition rates for stimuli composed
of two paper clip objects typically increase twofold compared to
previous experiments without attention (Neuron 1999;24(1):87-93).  To
achieve this improvement a depression of the V4 activity outside the
focus of attention by as little as 20\% proves to be sufficient. With
10\% activity modulation recognition still improves by 70\%.  We find
that the twofold increase in recognition rate is robust over a large
range of modulation strengths of the V4 activity.  We conclude that a
rather weak attentional modulation of the neural activity at the V4
level suffices to recognize multiple objects in the same display. Our
model will be extended to search for specific objects in cluttered
natural scenes and include biasing of the attention system in a
top-down manner.  },
booktitle = { Proc. 2002 Cognitive Neuroscience Society Meeting, San
Francisco, CA (Journal of Cognitive Neuroscience Vol.~B14)},
type                = { mod|bu },
file                 = { http://iLab.usc.edu/publications/doc/Walther_etal02cns.pdf }
}

@inproceedings{Pichon_Itti02aaai,
author={ E. Pichon and L. Itti },
title={Real-Time High-Performance Attention Focusing for Outdoors
 Mobile Beobots},
year={2002},
month={Mar},
pages={63},
booktitle={Proc. AAAI Spring Symposium, Stanford, CA (AAAI-TR-SS-02-04)},
abstract={When confronted with cluttered natural environments, animals still
perform orders of magnitude better than artificial vision systems in
tasks such as orienting, target detection, navigation and scene
understanding. The recent widespread availability of significant
computational resources, however, in particular through the deployment
of so-called ``Beowulf'' clusters of low-cost personal computers,
leaves us little excuse for the enormous gap still separating
biological from machine vision systems.
We describe a neuromorphic model of how our visual attention is
attracted towards conspicuous locations in a visual scene.  It
replicates processing in posterior parietal cortex and other brain
areas along the dorsal visual stream in the primate brain. The model
includes a bottom-up (image-based) computation of low-level color,
intensity, orientation and motion features, as well as a non-linear
spatial competition which enhances salient locations in each of these
feature channels.  All feature channels feed into a unique scalar
``saliency map'' which controls where to next focus attention
onto. Because it includes a detailed low-level vision front-end, the
model has been applied not only to laboratory stimuli, but also to a
wide variety of natural scenes. In addition to predicting a wealth of
psychophysical experiments, the model demonstrated remarkable
performance at detecting salient objects in outdoors imagery ---
sometimes exceeding human performance --- despite wide variations in
imaging conditions, targets to be detected, and environments.
The present paper focuses on a recently completed parallelization of
the model, which runs at 30 frames/s on a 16-CPU Beowulf cluster, and
on the enhancement of this real-time model to include motion cues in
addition to the previously studied color, intensity and orientation
cues. The parallel model architecture and its deployment onto Linux
Beowulf clusters are described, as well as several examples of
applications to real-time outdoors color video streams. Implementation
on a 4-CPU rugged high-speed mobile robot, a ``Beobot,'' is also
described. The model proves very robust at detecting salient targets
from live video streams, despite large possible variations in
illumination, rapid camera jitter, clutter, or omnipresent optical
flow (e.g., when used on a moving vehicle).  The success of this
approach suggests that the neuromorphic architecture described may
represent a robust and efficient real-time machine vision front-end,
which can be used in conjunction with more detailed localized object
recognition and identification algorithms to be applied at the
selected salient locations.},
type={mod|bu|cv|bb}
}

@incollection{Itti02hbtnn2e,
author = { L. Itti },
title = { Visual Attention },
year = {in press},
booktitle = { The Handbook of Brain Theory and Neural Networks, 2nd Ed. },
publisher = {MIT Press},
abstract={Selective visual attention is the mechanism by which we can
rapidly direct our gaze towards objects of interest in our visual
environment. From an evolutionary viewpoint, this rapid orienting
capability is critical in allowing living systems to quickly become
aware of possible preys, mates or predators in their cluttered visual
world.  It has become clear that attention guides where to look next
based on both bottom-up (image-based) and top-down (task-dependent)
cues.  As such, attention implements an information processing
bottleneck, only allowing a small part of the incoming sensory
information to reach short-term memory and visual awareness.  That is,
instead of attempting to fully process the massive sensory input in
parallel, nature has devised a serial strategy to achieve near
real-time performance despite limited computational capacity:
Attention allows us to break down the problem of scene understanding
into rapid series of computationally less demanding, localized visual
analysis problems.  These orienting and scene analysis functions of
attention are complemented by a feedback modulation of neural activity
at the location and for the visual attributes of the desired or
selected targets. This feedback is believed to be essential for
binding the different visual attributes of an object, such as color
and form, into a unitary percept. That is, attention not only serves
to select a location of interest, but also enhances the cortical
representation at that location. As such, focal visual attention is
often compared to a rapidly shiftable spotlight, which scans our
visual environment both overtly (with accompanying eye movements) or
covertly (with the eyes fixed).  This spotlight has been shown to have
variable size and shape depending on the target being attended to.
Finally, attention is involved in triggering behavior, and
consequently is intimately related to recognition, planning and motor
control. Of course, not all of vision is attentional, as we can derive
coarse understanding from presentations of visual scenes that are so
brief that they do not leave time for attention to explore the
scene. Vision thus appears to rely on sophisticated interactions
between coarse, massively parallel, full-field pre-attentive analysis
systems and the more detailed, circumscribed and sequential
attentional analysis system.  In what follows, we focus on several
critical aspects of selective visual attention: First, the brain area
involved in its control and deployment; second, the mechanisms by
which attention is attracted in a bottom-up or image-based manner
towards conspicuous or salient locations in our visual environment;
third, the mechanisms by which attention modulates the early sensory
representation of attended stimuli; fourth, the mechanisms for
top-down or voluntary deployment of attention towards visual locations
that may not necessarily be intrinsically conspicuous, but may be of
interest in solving a given visual task; and fifth, the interaction
between attention, object recognition and scene understanding.},
editor = {M. A. Arbib},
file = { http://iLab.usc.edu/publications/doc/Itti02hbtnn2e.pdf },
type={mod|bu|td|psy|rev|sc}
}

@inproceedings{Itti02vwsim,
author={L. Itti},
title={Neuromorphic Attentional Selection for Efficient Allocation of Computing Resources},
year={2002},
abstract={When confronted with cluttered natural environments, animals still perform orders of magnitude better than artificial vision systems in tasks such as orienting, target
detection, navigation and scene understanding. To better understand biological visual processing, we have developed a neuromorphic model of how our visual attention is attracted
towards conspicuous locations in a visual scene.  It replicates processing in the dorsal  (``where'') visual stream in the primate brain. The model includes a bottom-up
(image-based) computation of low-level color, intensity, orientation and motion features, as well as a non-linear spatial competition that enhances salient locations in each
feature channel.  All feature channels feed into a unique scalar ``saliency map'' which controls where to next focus attention. We show how our simple within-feature competition
for salience effectively suppresses strong but spatially widespread feature responses due to clutter.  The model robustly detects salient targets in live outdoors video streams,
despite large variations in illumination, clutter, and rapid egomotion. The success of this approach suggests that neuromorphic vision algorithms may prove unusually robust for
outdoors vision applications. Further, we argue that the massively parallel attentional selection implemented in our model may represent an efficient approach to the general
problem of allocating limited computational resources under conditions of sensory overload.},
booktitle={Proc. Virtual Worlds and Simulation Conference, San Antonio, Texas},
month={Jan},
type={mod|bu|cv}
}

@inproceedings{Itti02hvei,
author              = { L. Itti },
title = { Real-Time High-Performance Attention Focusing in Outdoors
Color Video Streams},
year                = {2002},
month={Jan},
pages={235-243},
abstract = { When confronted with cluttered natural environments,
animals still perform orders of magnitude better than artificial
vision systems in tasks such as orienting, target detection,
navigation and scene understanding. The recent widespread availability
of significant computational resources, however, in particular through
the deployment of so-called ``Beowulf'' clusters of low-cost personal
computers, leaves us little excuse for the enormous gap still
separating biological from machine vision systems.  We describe a
neuromorphic model of how our visual attention is attracted towards
conspicuous locations in a visual scene.  It replicates processing in
posterior parietal cortex and other brain areas along the dorsal
visual stream in the primate brain. The model includes a bottom-up
(image-based) computation of low-level color, intensity, orientation
and motion features, as well as a non-linear spatial competition which
enhances salient locations in each of these feature channels.  All
feature channels feed into a unique scalar ``saliency map'' which
controls where to next focus attention onto. Because it includes a
detailed low-level vision front-end, the model has been applied not
only to laboratory stimuli, but also to a wide variety of natural
scenes. In addition to predicting a wealth of psychophysical
experiments, the model demonstrated remarkable performance at
detecting salient objects in outdoors imagery --- sometimes exceeding
human performance --- despite wide variations in imaging conditions,
targets to be detected, and environments.  The present paper focuses
on a recently completed parallelization of the model, which runs at 30
frames/s on a 16-CPU Beowulf cluster, and on the enhancement of this
real-time model to include motion cues in addition to the previously
studied color, intensity and orientation cues. The parallel model
architecture and its deployment onto Linux Beowulf clusters are
described, as well as several examples of applications to real-time
outdoors color video streams. The model proves very robust at
detecting salient targets from live video streams, despite large
possible variations in illumination, rapid camera jitter, clutter, or
omnipresent optical flow (e.g., when used on a moving vehicle).  The
success of this approach suggests that the neuromorphic architecture
described may represent a robust and efficient real-time machine
vision front-end, which can be used in conjunction with more detailed
localized object recognition and identification algorithms to be
applied at the selected salient locations.},
booktitle = { Proc. SPIE Human Vision and Electronic Imaging VII
(HVEI'02), San Jose, CA },
editor={B. Rogowitz and T. N. Pappas},
type                = { mod|bu|cv },
file                 = { http://iLab.usc.edu/publications/doc/Itti02hvei.pdf }
}



@incollection{Itti_etal02nips,
title={Modeling the Modulatory Effect of Attention on Human Spatial Vision},
author={L. Itti and J. Braun and C. Koch},
abstract={We present new simulation results, in which a computational model of
  interacting visual neurons simultaneously predicts the modulation of
  spatial vision thresholds by focal visual attention, for five
  dual-task human psychophysics experiments. This new study
  complements our previous findings that attention activates a
  winner-take-all competition among early visual neurons within one
  cortical hypercolumn.  This ``intensified competition'' hypothesis
  assumed that attention equally affects all neurons, and yielded two
  single-unit predictions: an increase in gain and a sharpening of
  tuning with attention. While both effects have been separately
  observed in electrophysiology, no single-unit study has yet shown
  them simultaneously.  Hence, we here explore whether our model could
  still predict our data if attention might only modulate neuronal
  gain, but do so non-uniformly across neurons and tasks.
  Specifically, we investigate whether modulating the gain of only the
  neurons that are loudest, best-tuned, or most informative about the
  stimulus, or of all neurons equally but in a task-dependent manner,
  may account for the data.  We find that none of these hypotheses
  yields predictions as plausible as the intensified competition
  hypothesis, hence providing additional support for our original
  findings.},
year={2002},
publisher           = { MIT Press },
editor={T. G. Dietterich and S. Becker and Z. Ghahramani},
address             = { Cambridge, MA },
booktitle           = { Advances in Neural Information Processing Systems, Vol.
                        14 },
type                = { mod|td|psy },
file                 = { http://iLab.usc.edu/publications/doc/Itti_etal02nips.pdf }
}

@inproceedings{Miau_etal01spie,
author              = { F. Miau and C. Papageorgiou and L. Itti },
title               = { Neuromorphic algorithms for computer vision and attention },
year                = { 2001 },
month={Nov},
keywords            = { Visual attention | object recognition | scene analysis |
                        bottom-up | top-down },
abstract            = { We describe an integrated vision system which reliably detects
                        persons in static color natural scenes, or other targets
                        among distracting objects. The system is built upon the
                        biologically-inspired synergy between two processing stages:
                        A fast trainable visual attention front-end (``where''),
                        which rapidly selects a restricted number of conspicuous
                        image locations, and a computationally expensive object
                        recognition back-end (``what''), which determines whether
                        the selected locations are targets of interest. We experiment
                        with two recognition back-ends: One uses a support vector
                        machine algorithm and achieves highly reliable recognition
                        of pedestrians in natural scenes, but is not particularly
                        biologically plausible, while the other is directly inspired
                        from the neurobiology of inferotemporal cortex, but is not
                        yet as robust with natural images. Integrating the attention
                        and recognition algorithms yields substantial speedup over
                        exhaustive search, while preserving detection rate. The
                        success of this approach demonstrates that using a biological
                        attention-based strategy to guide an object recognition
                        system may represent an efficient strategy for rapid scene
                        analysis. },
booktitle           = { Proc. SPIE 46 Annual International Symposium on Optical
                        Science and Technology },
volume={4479},
pages={12-23},
type                = { bu|mod|cv },
file                = { http://iLab.usc.edu/publications/doc/Miau_etal01spie.pdf }
}

@inproceedings{Miau_Itti01embs,
author              = { F. Miau and L. Itti },
title               = { A Neural Model Combining Attentional Orienting to Object
                        Recognition: Preliminary Explorations on the Interplay Between
                        Where and What },
year                = { 2001 },
month={Oct},
keywords            = { Visual attention | object recognition | scene analysis |
                        bottom-up | top-down },
abstract            = { We propose a model of primate vision that integrates both
                        an attentional orienting (``where'') pathway and an object
                        recognition (``what'') pathway. The fast visual attention
                        front-end rapidly selects the few most conspicuous image
                        locations, and the slower object recognition back-end identifies
                        objects at the selected locations. The model is applied
                        to classical visual search tasks, consisting of finding
                        a specific target among an array of distracting visual patterns
                        (e.g., a circle among many squares). The encouraging results
                        obtained, in which substantial speedup is achieved by the
                        combined attention-recognition model while maintaining good
                        recognition performance compared to an exhaustive search,
                        suggest that the biologically-inspired architecture proposed
                        represents an efficient solution to the difficult problem
                        of rapid scene analysis. },
booktitle           = { Proc. IEEE Engineering in Medicine and Biology Society (EMBS), Istanbul, Turkey },
type                = { bu|mod|cv },
note={Winner of the Excellence in Neural Engineering Travel Award},
file                = { http://iLab.usc.edu/publications/doc/Miau_Itti01embs.pdf }
}

@article{Itti_etal01jni,
author              = { L. Itti and L. Chang and T. Ernst },
title               = { Segmentation of Progressive Multifocal Leukoencephalopathy
                        Lesions in Fluid-Attenuated Inversion Recovery
 Magnetic Resonance Imaging },
journal             = { Journal of Neuroimaging },
year                = { 2001 },
month = {Oct},
volume={11},
number={4},
pages={412-417},
abstract            = { Background and Purpose: To compare the reproducibility of
                        manual and a semi-automated technique for the quantitation
                        of white matter lesions in magnetic resonance imaging. Methods:
                        Volumes of white matter lesions were determined using FLAIR
                        MRI in 23 AIDS patients with progressive multifocal leukoencephalopathy.
                        Manual outlining was compared to an automated method based
                        on region growing and adaptive thresholding. Results: Lesion
                        volumes from the two methods correlated well (61 lesions,
                        r=0.99, p<0.0001), although the volumes differed substantially
                        (12.8 +/- 13.7%, mean +/- S.D). Interscan intrasubject reproducibility
                        was better for the automated than the manual method (2.9
                        +/- 3.2% vs. 12.4 +/- 16.2% volume difference, p=0.02).
                        Conclusion: The automated algorithm appeared more reproducible,
                        which renders it superior to the manual method for longitudinal
                        studies. },
type                = { mip|med },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal01jni.pdf },
url                 = { http://iLab.usc.edu/publications/doc/Itti_etal01jni/ }
}

@article{Itti_etal01oe,
author              = { L. Itti and C. Gold and C. Koch },
title               = { Visual Attention and Target Detection in Cluttered Natural
                        Scenes },
journal             = { Optical Engineering },
volume={40},
number={9},
pages={1784-1793},
year                = { 2001 },
month={Sep},
keywords            = { Visual attention | saliency | preattentive | inhibition
                        of return | winner-take-all | bottom-up | natural scene },
abstract            = { Rather than attempting to fully interpret visual scenes
                        in a parallel fashion, biological systems appear to employ
                        a serial strategy by which an attentional spotlight rapidly
                        selects circumscribed regions in the scene for further analysis.
                        The spatiotemporal deploy- ment of attention has been shown
                        to be controlled by both bottom-up (image-based) and top-down
                        (volitional) cues. We describe a detailed neuromimetic computer
                        implementation of a bottom-up scheme for the control of
                        visual attention, focusing on the problem of combining information
                        across modalities, here orientation, intensity and color
                        information, in a purely stimulus-driven manner. We have
                        applied this model to a wide range of target detection tasks,
                        using synthetic and natural stimuli. Performance has however
                        remained difficult to objectively evaluate on natural scenes,
                        because no objective reference was available for comparison.
                        We here present predicted search times for our model on
                        the Search2 database of rural scenes containing a military
                        vehicle. Overall, we found a poor correlation between human
                        and model search times. Further analysis, however, revealed
                        that in 75 percent of the images, the model appeared to
                        detect the target faster than humans (for comparison, we
                        calibrated the model's arbitrary internal time frame such
                        that 2-4 image locations were visited per second). It hence
                        seems that this model, which had originally been designed
                        not to find small, hidden military vehicles, but rather
                        to find the few most obviously conspicuous objects in an
                        image, performed as an efficient target detector on the
                        Search2 dataset. Further developments of the model are finally
                        explored, in particular through a more formal treatment
                        of the difficult problem of extracting suitable low-level
                        features to be fed into the saliency map. },
type                = { bu | mod | cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal01oe.pdf }
}

@article{Chang_etal01,
author              = { L. Chang and O. Speck and E. N. Miller and J. Braun and
                        J. Jovicich and C. Koch and L. Itti and T. Ernst },
title               = { Neural Correlates of Attention and Working Memory Deficits
                        in HIV Patients },
journal             = {Neurology},
year                = { 2001 },
volume={57},
number={6},
pages={1001-1007},
month={Sep},
abstract            = { Objectives: To evaluate the neural correlates of attention
                        and working memory deficits in patients infected with HIV-1.
                        Method: Functional magnetic resonance imaging (fMRI) was
                        used to evaluate brain activity in 11 HIV-patients and 11
                        age, gender, education and handedness-matched seronegative
                        subjects, while performing a battery of tasks that required
                        different levels of attention for working memory. Results:
                        HIV-patients showed greater brain activation (BOLD signal
                        changes) in some brain regions compared to control subjects
                        while performing the same tasks. For the simpler tasks,
                        HIV patients showed greater activation in the parietal regions.
                        However, with more difficult tasks, HIV patients showed
                        greater activation additionally in the frontal lobes. Reaction
                        times during these tasks were slower but accuracies were
                        similar in the HIV patients compared to control subjects.
                        Conclusion: Injury to the neural substrate due to the HIV
                        infection may necessitate greater attentional modulation
                        of the neural circuits, hence a greater usage of the brain
                        reserve; additional activation of the frontal lobes is required
                        to perform the more complex tasks. The task-dependent increased
                        frontal activation in the HIV patients suggests that the
                        neural correlate of attentional deficits may be excessive
                        attentional modulation as a result of frontostriatal brain
                        injury. },
file                = { http://iLab.usc.edu/publications/doc/Chang_etal01.pdf},
type                = { mip | med | td }
}

@incollection{Niebur_etal01,
author              = { E. Niebur and L. Itti and C. Koch },
title               = { Controlling the Focus of Visual Selective Attention },
year                = { 2001 },
month = {Aug},
abstract            = { Selecting only a subset of the available sensory information
                        before further detailed processing is crucial for efficient
                        perception. In the visual modality, this selection is frequently
                        implemented by suppressing information outside a spatially
                        circumscribed region of the visual field, the so-called
                        ``focus of attention.'' The model for the control of the
                        focus of attention in primates presented here is based on
                        a ``Saliency Map'' which is a topographic representation
                        of the instantaneous saliency of the visual scene. },
editor              = { L. Van Hemmen and E. Domany and J. Cowan},
publisher           = { Springer Verlag },
booktitle           = { Models of Neural Networks IV },
type                = { bu|mod|cv },
file                = { http://iLab.usc.edu/publications/doc/Niebur_etal01.pdf }
}

@patent{Koch_Itti01,
author              = { C. Koch and L. Itti },
title               = { Computation of Intrinsic Perceptual Saliency in Visual Environments,
                        and Applications },
month = { Jul },
year                = 2001,
abstract            = { Detection of image salience in a visual display of an image.
                        The image is analyzed at multiple spatial scales and over
                        multiple
                        feature channels to determine the likely salience of different
                        portions of the image. One application for the system is
                        in an
                        advertising context. The detection may be improved by second
                        order
                        statistics, e.g. mean and standard deviations of different
                        image
                        portions relative to other portions. Different edges may
                        be
                        considered as being extended edges by looking at the edges
                        over
                        multiple spatial scales. One set of feature channels can
                        be optimized
                        for use in moving images, and can detect motion or flicker.
                        The
                        images can be obtained over multiple spectral ranges and
                        the user can
                        be instructed about how to maximize the saliency. This can
                        be applied
                        to automatically evaluate and optimize sales or advertisement
                        displays. },
note                = { Patent pending. Filed July 23, 2001, following provisional
                        applications No. 60/274,674 filed March 8, 2001 and 60/288,724
                        filed May 4, 2001. },
organization        = { California Institute of Technology, Pasadena, California },
type                = { bu|mod|cv }
}

@incollection{Braun_etal01,
author              = { J. Braun and C. Koch and D. K. Lee and L. Itti },
title               = { Perceptual Consequences of Multilevel Selection },
pages               = { 215-242 },
month = { Apr },
year                = 2001,
keywords            = { visual attention },
abstract            = { The neurobiology and psychology of attention have much to
                        learn from each other. Neurobiologists recognize that responses
                        in sensory cortex depend on the behavioral relevance of
                        a stimulus, but have few ways to study how perception changes
                        as a result. Psychologists have the conceptual and methodological
                        tools to do just that, but are confounded by the multiple
                        interpretations and theoretical ambiguities. This book attempts
                        to bridge the two fields and to derive a comprehensive theory
                        of attention from both neurobiological and psychological
                        data. It highlights situations where attention can be seen
                        to alter both neural activity and psychophysical performance/phenomenal
                        experience. This ``bicultural'' approach contributes not
                        only to attention research but to the larger goal of linking
                        neural activity to conscious experience. The book focuses
                        mainly on the effects of visual attention on the ventral
                        and dorsal streams of visual cortex in humans and monkeys
                        and the associated changes in visual performance. Several
                        larger findings emerge: attention may involve more than
                        one neural system; attention modulates all stages of cortical
                        visual processing; the effect of attention is constrained
                        by the intrinsic connectivity of cortex and the resulting
                        contextual interactions; and the notion of a ``saliency
                        map'' remains central to thinking about visual attention.
                        The book also considers several approaches to evaluating
                        the same variable through different methods, such as behavioral
                        measurements, functional imaging, and single-unit recording. },
note                = { ISBN: 0-262-02493-4, 344 pages, Hardcover (cloth). },
editor              = { J. Braun and C. Koch and J. Davis },
publisher           = { MIT Press },
address             = { Cambridge, MA },
booktitle           = { Visual Attention and Cortical Circuits },
type                = { mod|td|psy }
}

@article{Itti_Koch01nrn,
author              = { L. Itti and C. Koch },
title               = { Computational Modeling of Visual Attention },
journal             = { Nature Reviews Neuroscience },
volume              = 2,
number              = 3,
pages               = { 194-203 },
month = { Mar },
year                = 2001,
abstract            = { Five important trends have emerged from recent work on computational
                        models of focal visual attention that emphasize the bottom-up,
                        image-based control of attentional deployment. First, the
                        perceptual saliency of stimuli critically depends on the
                        surrounding context. Second, a unique saliency map that
                        topographically encodes for stimulus conspicuity over the
                        visual scene has proved to be an efficient and plausible
                        bottom-up control strategy. Third, inhibition of return,
                        the process by which the currently attended location is
                        prevented from being attended again, is a crucial element
                        of attentional deployment. Fourth, attention and eye movements
                        tightly interplay, posing computational challenges with
                        respect to the coordinate system used to control attention.
                        And last, scene understanding and object recognition strongly
                        constrain the selection of attended locations. Insights
                        from these five key areas provide a framework for a computational
                        and neurobiological understanding of visual attention. },
type                = { mod|bu|td|rev },
file                = { http://iLab.usc.edu/publications/doc/Itti_Koch01nrn.pdf }
}

@article{Itti_etal01mrm,
author              = { L. Itti and L. Chang and T. Ernst },
title               = { Automatic scan prescription for brain MRI },
journal             = { Magnetic Resonance in Medicine },
volume              = 45,
number              = 3,
pages               = { 486-494 },
month = { Mar },
year                = 2001,
abstract            = { Diagnostic brain MRI scans are usually performed by trained
                        medical technologists who manually prescribe the position
                        and orientation of a scanning volume. In this study, a fully
                        automatic computer algorithm is described which compensates
                        for variable patient positioning and acquires brain MRI
                        scans in a predefined reference orientation. The method
                        involves acquiring a rapid water-only pilot scan, segmenting
                        the brain surface, and matching it to a reference surface.
                        The inverse matching transformation is then used to adapt
                        a geometric description of the desired scanning volume,
                        defined relative to the reference surface, to the current
                        patient. Both pilot scan and processing are performed within
                        30 sec. The method was tested in 25 subjects, and consistently
                        recovered orientation differences between the reference
                        and each subject to within +/-5 degrees. Compared to manual
                        prescription, automatic scan prescription promises many
                        potential benefits, including reduced scan times, reproducible
                        scan orientations along anatomically preferable orientations,
                        and better reproducibility for longitudinal studies. },
address             = { Harbor UCLA Research and Education Institute, Torrance,
                        California. },
type                = { mip|fmri },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal01mrm.pdf }
}

@article{Itti_Koch01ei,
author              = { L. Itti and C. Koch },
title               = { Feature Combination Strategies for Saliency-Based Visual
                        Attention Systems },
journal             = { Journal of Electronic Imaging },
volume              = 10,
number              = 1,
pages               = { 161-169 },
month = { Jan },
year                = 2001,
keywords            = { Attention | saliency | target detection | feature integration
                        | learning },
abstract            = { Bottom-up or saliency-based visual attention allows primates
                        to detect non-specific conspicuous targets in cluttered
                        scenes. A classical metaphor, derived from electrophysiological
                        and psychophysical studies, describes attention as a rapidly
                        shiftable ``spotlight''. We use a model that reproduces
                        the attentional scanpaths of this spotlight. Simple multi-scale
                        ``feature maps'' detect local spatial discontinuities in
                        intensity, color, and orientation, and are combined into
                        a unique ``master'' or ``saliency'' map. The saliency map
                        is sequentially scanned, in order of decreasing saliency,
                        by the focus of attention. We here study the problem of
                        combining feature maps, from different visual modalities
                        (such as color and orientation), into a unique saliency
                        map. Four combination strategies are compared using three
                        databases of natural color images: (1) Simple normalized
                        summation, (2) linear combination with learned weights,
                        (3) global non-linear normalization followed by summation,
                        and (4) local non-linear competition between salient locations
                        followed by summation. Performance was measured as the number
                        of false detections before the most salient target was found.
                        Strategy (1) always yielded poorest performance and (2)
                        best performance, with a 3 to 8-fold improvement in time
                        to find a salient target. However, (2) yielded specialized
                        systems with poor generalization. Interestingly, strategy
                        (4) and its simplified, computationally efficient approximation
                        (3) yielded significantly better performance than (1), with
                        up to 4-fold improvement, while preserving generality. },
type                = { bu|mod|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_Koch01ei.pdf }
}

@article{Ernst_etal00,
author              = { T. Ernst and E. Itti and L. Itti and L. Chang },
title               = { Changes in cerebral metabolism are detected prior to perfusion
                        changes in early HIV-CMC: A coregistered (1)H MRS and SPECT
                        study },
journal             = { Journal of Magnetic Resonance Imaging },
volume              = 12,
number              = 6,
pages               = { 859-865 },
month = { Dec },
year                = 2000,
abstract            = { Human immunodeficiency virus-cognitive motor complex (HIV-CMC),
                        a common complication of the acquired immunodeficiency syndrome
                        (AIDS), is characterized by progressive cognitive impairment
                        and motor dysfunction. Functional imaging methods, such
                        as single-photon emission computed tomography (SPECT) and
                        proton magnetic resonance spectroscopy ((1)H-MRS), have
                        been applied to assess the severity of brain injury. However,
                        it is unclear which of these two methods is more sensitive
                        in detecting brain abnormalities in patients with early
                        HIV-CMC. Twenty-four HIV-CMC patients were compared with
                        34 healthy subjects; each had quantitative SPECT ((133)Xenon-calibrated
                        (99m)Tc-HMPAO) and quantitative (1)H-MRS. Both modalities
                        were co-registered in order to assess regional cerebral
                        blood flow (rCBF) and metabolite concentrations within the
                        same voxel of interest in four brain regions (midfrontal
                        and midparietal gray matter, temporoparietal white matter,
                        and basal ganglia). On SPECT, only the temporoparietal white
                        matter showed a trend for decreased rCBF in HIV-CMC patients
                        (-13%, P = 0.06). On MRS, HIV-CMC patients showed significantly
                        reduced creatine concentration in the basal ganglia (-8%,
                        P = 0.008), as well as increased myoinositol concentrations
                        in the basal ganglia (+25%, P = 0.01) and the temporoparietal
                        white matter (+18%, P = 0.08). There was no significant
                        correlation between SPECT and MRS variables in the patients
                        in any region. (1)H MRS showed abnormal neurochemistry in
                        the basal ganglia, whereas rCBF on SPECT was normal in the
                        same region. This finding suggests that metabolite concentrations
                        on (1)H MRS are better surrogate markers than rCBF measurements
                        with SPECT for the evaluation of brain injury in early HIV-CMC. },
address             = { Department of Radiology, Harbor-UCLA Medical Center, Torrance,
                        California 90502, USA. },
type                = { mip|med },
file                = { http://iLab.usc.edu/publications/doc/Ernst_etal00.pdf }
}

@article{Itti_etal00josa,
author              = { L. Itti and C. Koch and J. Braun },
title               = { Revisiting Spatial Vision: Towards a Unifying Model },
journal             = { Journal of the Optical Society of America, JOSA-A },
volume              = 17,
number              = 11,
pages               = { 1899-1917 },
month = { Nov },
year                = 2000,
abstract            = { We report contrast detection, contrast increment, contrast
                        masking, orientation discrimination and spatial frequency
                        discrimination thresholds for spatially localized stimuli
                        at 4deg of eccentricity. Our stimulus geometry emphasizes
                        interactions among overlapping visual filters and differs
                        from that used in previous threshold measurements, which
                        also admits interactions between distant filters. We quantitatively
                        account for all measurements by simulating a small population
                        of overlapping visual filters interacting through divisive
                        inhibition. We depart from previous models of this kind
                        in the parameters of divisive inhibition and in using a
                        statistically efficient decision stage based on Fisher information.
                        The success of this unified account suggests that, contrary
                        to Bowne (1990), spatial vision thresholds reflect a single
                        level of processing, perhaps as early as primary visual
                        cortex. },
type                = { psy|mod },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal00josa.pdf }
}

@inproceedings{Itti_etal00arvo,
author              = { L. Itti and J. Braun and C. Koch },
title               = { Single-Filter Gain Changes and Attentional Threshold Modulation },
volume              = 41,
number              = 4,
pages               = {S39},
month = { Mar },
year                = 2000,
abstract            = { Purpose: We previously used a simple model to interpret
                        attentional modulation of human psychophysical thresholds
                        for pattern discrimination. ``Fully'' and ``poorly'' attended
                        thresholds were obtained using a dual-task paradigm (Lee
                        et al., Nature Nsci'99), for increment contrast discrimination
                        (ICD), orientation and spatial frequency discriminations,
                        and for two contrast masking tasks. The model used 60 linear
                        filters (5 scales, 12 orientations) followed by Heeger-type
                        divisive gain control and statistically efficient decision.
                        It accounted for all the data (Itti et al., ARVO'98) by
                        assuming indiscriminate intensified competition among all
                        filters, predicting both a 3-fold gain increase and a 35%
                        sharpening of tuning with attention. Here we explore whether
                        a simpler explanation involving only gain changes is tenable
                        as well. Since a unique gain modulation, identical for all
                        filters and tasks, failed to predict our data, we investigate
                        more specific attentional feedback, affecting the gain of
                        task-dependent sub-populations of filters. Methods: We still
                        assume identical modulation for all tasks, but now consider
                        that attention only affects the gain of the single filter
                        (i) best-tuned to, (ii) responding maximally to, or (iii)
                        most informative about a given stimulus. Other filters are
                        unaffected by attention. A downhill simplex with simulated
                        annealing overhead simultaneously fits to the data both
                        the unique, task-independent attentional gain factor and
                        our model's 10 intrinsic parameters (filter tuning, transducer
                        function, filter interaction, response variance), for all
                        tasks in both attentional conditions (64 datapoints). Results
                        & Conclusion: Hypotheses (i) and (ii) yielded qualitatively
                        incorrect fits with negligible modulation in at least two
                        tasks. Residual fit error was 150--300% higher than under
                        the assumption of intensified competition. Hypothesis (iii)
                        yielded a qualitatively reasonable fit (though not predicting
                        the well-known ``dipper'' in ICD), yet was quantitatively
                        poor (75% higher error). We conclude that the gain-only
                        manipulations studied do not simultaneously reproduce attentional
                        modulation as well as intensified competition. },
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        2000) },
type                = { td|mod },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal00arvo.pdf }
}

@inproceedings{Tehrani_etal00,
author              = { F. Tehrani and L. Itti and C. Koch },
title               = { Visual Search Asymmetries Reproduced by Simple Model },
volume              = 41,
number              = 4,
pages               = {S423},
month = { Mar },
year                = 2000,
abstract            = { Purpose: In some instances of visual search, where human
                        observers detect the presence or absence of a special ``target''
                        visual pattern in an array of identical ``distractor'' patterns,
                        search time asymmetries have been reported when target and
                        distractor patterns are interchanged. A classical explanation
                        for this finding is that targets which contain ``richer
                        features'' are easier to find among simpler distractors
                        than the opposite. For example, a curved line segment is
                        detected faster among straight segments than the opposite,
                        presumably because it has the added property of curvature.
                        Here we test whether a simple computational model of bottom-up
                        attention reproduces such asymmetries. Methods: Our model
                        implements a number of simple multiscale ``feature maps''
                        selective for colors, orientations and intensity, and combines
                        them into a unique topographic ``saliency map'' which guides
                        attention (Itti et al., IEEE-PAMI, 1998). Stimulus arrays
                        were generated by an automatic program. Search elements
                        were randomly jittered by up to 60% of their size and rotated
                        by up to +/-10deg. Uniform color speckle noise with 10%
                        probability was finally added. For twenty target/distractor
                        pairs (e.g., ``Q'' among ``O'', or open among closed cicles),
                        we generated twenty instances of arrays containing 4x4 to
                        10x10 elements (seven sizes in total). The resulting 5600
                        images were evaluated by our model, and simulated search
                        times were collected. Results & Conclusion: For control
                        target/distractor pairs, for which no asymmetry is found
                        in humans, the model did not either exhibit spurious asymmetries.
                        For pairs yielding asymmetry in humans, the model generally
                        reproduced the asymmetry. With some pairs however, the model
                        initially predicted an opposite asymmetry; careful examination
                        of the model's internals revealed that such failure was
                        due to luminance imbalance between target and distractor.
                        After luminance correction, the correct asymmetries were
                        obtained. In all asymmetry cases, the model showed significantly
                        stronger activity in at least one feature map for the easily-found
                        target. Our simulations hence confirm in a computational
                        manner that asymmetries may be due to an ``added property''
                        in the target that is easy to detect. },
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        2000) },
type                = { bu|mod }
}

@inproceedings{Egner_etal00,
author              = { S. Egner and L. Itti and C. R. Scheier },
title               = { Comparing attention models with different types of behavior
                        data },
volume              = 41,
number              = 4,
pages               = {S39},
month = { Mar },
year                = 2000,
abstract            = { Purpose: While looking at an image, a human observer generates
                        a sequence of attentional shifts between different image
                        locations. Different models of visual attention attempt
                        to predict these shifts. The goal of our ongoing project
                        is to evaluate different models by comparing their predicted
                        shifts of attention to the shifts produced by human observers.
                        Methods: The main challenge for our study is that attention
                        models typically predict covert shifts of attention, which
                        can not be measured directly from an observer's behavior.
                        What can be measured, for instance eye movements, is always
                        a result of response-specific (e.g. the oculo-motor system)
                        and non-specific (e.g. attentional) factors. To infer the
                        non-response-specific factors, we recorded different types
                        of responses, eye movements, finger pointing, and mouse
                        clicks for the same stimuli. Each stimulus, a search/pop-out
                        display, a natural scene or a web page, was presented for
                        four seconds. Responses that highly correlated between different
                        modalities were assumed to reflect attentional processes.
                        The behavior data was transformed into image coordinates
                        where it could be compared the models' predictions. We used
                        a local feature contrast based saliency measurement as a
                        baseline model and the model by Itti and Koch (1998). Other
                        models can be integrated in the same way. We computed how
                        well the distribution of responses from one response system
                        could predict the responses from another response system
                        or from a model. Results: (1) Distributions produced by
                        different response systems are highly correlated. (2) The
                        similarity between responses and model predictions strongly
                        depends on the stimulus category, but for all stimulus categories,
                        the model by Itti and Koch produces better predictions than
                        the baseline model. Conclusions: The high similarity between
                        response modalities indicates that the responses reflect
                        a common underlying, presumably attentional, process. We
                        suggest that mouse clicks are a particularly easy way to
                        gather attentional data. The model by Itti and Koch is favorable
                        over the baseline model. Some model improvements that would
                        lead to an even higher agreement with our empirical data
                        are discussed. },
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        2000) },
type                = { bu|mod|psy }
}

@article{Itti_Koch00vr,
author              = { L. Itti and C. Koch },
title               = { A saliency-based search mechanism for overt and covert shifts
                        of visual attention },
journal             = { Vision Research },
volume              = 40,
number              = { 10-12 },
pages               = { 1489-1506 },
month = { May },
year                = 2000,
keywords            = { Adolescence | Adult | Attention/*physiology | Color Perception/physiology
                        | Female | Human | Male | Middle Age | *Models, Neurological
                        | *Models, Psychological | Psychophysics | Support, Non-U.S.
                        Gov't | Support, U.S. Gov't, Non-P.H.S. | Support, U.S.
                        Gov't, P.H.S. | Visual Perception/*physiology | 2000/08/12
                        11:00 },
abstract            = { Most models of visual search, whether involving overt eye
                        movements or covert shifts of attention, are based on the
                        concept of a saliency map, that is, an explicit two-dimensional
                        map that encodes the saliency or conspicuity of objects
                        in the visual environment. Competition among neurons in
                        this map gives rise to a single winning location that corresponds
                        to the next attended target. Inhibiting this location automatically
                        allows the system to attend to the next most salient location.
                        We describe a detailed computer implementation of such a
                        scheme, focusing on the problem of combining information
                        across modalities, here orientation, intensity and color
                        information, in a purely stimulus-driven manner. The model
                        is applied to common psychophysical stimuli as well as to
                        a very demanding visual search task. Its successful performance
                        is used to address the extent to which the primate visual
                        system carries out visual search via one or more such saliency
                        maps and how this can be tested. },
address             = { Computation and Neural Systems Program, Division of Biology,
                        California Institute of Technology, Mail-Code 139-74, Pasadena,
                        CA 91125, USA. },
type                = { bu|mod|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_Koch00vr.pdf },
url                 = { http://klab.caltech.edu/~itti/attention/publications/00_VR/paper_twocol.html }
}

@article{Selim00,
author              = { J. Selim },
title               = { Hidden in Plain Sight },
journal             = { Discover Magazine },
pages               = 16,
month = { May },
year                = 2000,
keywords            = { Visual perception | research },
abstract            = { Your vision is terrible-you just don't know it. A camera
                        took the picture at left. Laurent Itti, a postgraduate researcher
                        in Caltech's Computation and Neural Systems Program, then
                        computer-altered the photo to show the corresponding image
                        that forms inside the eye, at right. Light-detecting cells
                        in the retina are tightly packed only in a small central
                        region. The density of those cells decreases toward the
                        outer edges of the retina, so peripheral vision becomes
                        less crisp. And the location where the optic nerve meets
                        the retina creates a perpetual blind spot. ''We move our
                        eyes three to five times per second, and we remember the
                        objects we've just seen, so we think we see better than
                        we actually do,'' says Itti. },
note                = { Brief scientific comment with illustrations. },
type                = { mod|cv },
url                 = { http://klab.caltech.edu/~itti/retina/ }
}

@inproceedings{Ernst_etal00ismrm,
author              = { T. Ernst and L. Itti and L. Chang },
title               = { Automatic Scan Prescription for Brain MRI },
pages               = 1385,
month = { Apr },
year                = 2000,
booktitle           = { Proceedings of the 8th Annual Meeting of the International
                        Society for Magnetic Resonance in Medicine (ISMRM'2000) },
type                = {mip}
}

@article{Chang_etal00,
author              = { L. Chang and C. S. Grob and T. Ernst and L. Itti and F.
                        S. Mishkin and R. Jose-Melchor and R. E. Poland },
title               = { Effect of ecstasy [3,4-methylenedioxymethamphetamine (MDMA)]
                        on cerebral blood flow: a co-registered SPECT and MRI study },
journal             = { Psychiatry Research },
volume              = 98,
number              = 1,
pages               = { 15-28 },
month = { Feb },
year                = 2000,
keywords            = { Adult | Brain/*drug effects/pathology/radionuclide imaging
                        | Case-Control Studies | Cerebrovascular Circulation/*drug
                        effects | Dose-Response Relationship, Drug | Female | Human
                        | *Magnetic Resonance Imaging | Male | Middle Age | N-Methyl-3,4-methylenedioxyamphetamine/administration
                        & dosage/*adverse | effects | Radiopharmaceuticals/diagnostic
                        use | Serotonin Agents/administration & dosage/*adverse
                        effects | Support, Non-U.S. Gov't | Support, U.S. Gov't,
                        P.H.S. | Technetium Tc 99m Exametazime/diagnostic use |
                        Time Factors | *Tomography, Emission-Computed, Single-Photon
                        | 2000/05/16 09:00 },
abstract            = { 3,4-methylenedioxymethamphetamine (MDMA), an illicit recreational
                        drug, damages serotonergic nerve endings. Since the cerebrovasculature
                        is regulated partly by the serotonergic system, MDMA may
                        affect cerebral blood flow (CBF) in humans. We evaluated
                        21 abstinent recreational MDMA users and 21 age- and gender-matched
                        healthy subjects with brain SPECT and MRI. Ten of the MDMA
                        subjects also had repeat SPECT and MRI after receiving two
                        doses of MDMA. Abstinent MDMA users showed no significantly
                        different global or regional CBF (rCBF) compared to the
                        control subjects. However, within 3 weeks after MDMA administration,
                        rCBF remained decreased in the visual cortex, the caudate,
                        the superior parietal and dorsolateral frontal regions compared
                        to baseline rCBF. The decreased rCBF tended to be more pronounced
                        in subjects who received the higher dosage of MDMA. Two
                        subjects who were scanned at 2-3 months after MDMA administration
                        showed increased rather than decreased rCBF. Low-dose recreational
                        MDMA use does not cause detectable persistent rCBF changes
                        in humans. The lack of long-term rCBF changes may be due
                        to a non-significant effect of serotonergic deficits on
                        rCBF, or regeneration of serotonergic nerve terminals. The
                        subacute decrease in rCBF after MDMA administration may
                        be due to the direct effect of MDMA on the serotonergic
                        system or the indirect effects of its metabolites on the
                        dopaminergic system; the preliminary data suggest these
                        effects may be transient. },
address             = { Department of Neurology, UCLA School of Medicine, Harbor-UCLA
                        Medical Center, 1000 W. Carson Street, B-4, Torrance, CA
                        90509, USA. linda_chang@humc.edu },
type                = { mip|fmri|med }
}

@phdthesis{Itti00phd,
author              = { L. Itti },
title               = { Models of Bottom-Up and Top-Down Visual Attention },
month = { Jan },
year                = 2000,
keywords            = { Visual Attention | Bottom-Up | Top-Down | Modeling | Spatial
                        Vision | Human Psychophysics | Neural Networks | Automatic
                        Target Recognition (ATR) | Visual Search | Eye Movements },
abstract            = { When we observe our visual environment, we do not perceive
                        all its components as being equally interesting. Some objects
                        automatically and effortlessly ``pop-out'' from their surroundings,
                        that is, they draw our visual attention, in a `bottom-up''
                        manner, towards them. In a first approximation, focal visual
                        attention acts as a rapidly shiftable ``spotlight,'' which
                        allows only the selected information to reach higher levels
                        of processing and representation. Most models of the bottom-up
                        control of attention are based on the concept of a saliency
                        map, that is, an explicit two-dimensional map that encodes
                        the conspicuity of objects in the visual environment. Competition
                        among neurons in this map gives rise to a single winning
                        location that corresponds to the next attended target. Inhibiting
                        this location automatically allows the system to attend
                        to the next most salient location. A first body of work
                        in this thesis describes a detailed computer implementation
                        of such a scheme, focusing on the problem of combining information
                        across modalities, here orientation, intensity and color
                        information, in a purely stimulus-driven manner. The model
                        is applied to common psychophysical stimuli as well as to
                        very demanding visual search tasks. Its successful performance
                        is used to address the extent to which the primate visual
                        system carries out visual search via one or more such saliency
                        maps and how this can be tested. We next address the question
                        of what happens once our attention is focused onto a restricted
                        part of our visual field. There is mounting experimental
                        evidence that attention is far more sophisticated than a
                        simple feed-forward spatially-selective filtering process.
                        Indeed, visual processing appears to be significantly different
                        inside the attentional spotlight than outside. That is,
                        in addition to its properties as a feed-forward information
                        processing and transmission bottleneck, focal visual attention
                        feeds back and locally modulates, in a ``top-down'' manner,
                        the visual processing and representation of selected objects.
                        The second body of work presented in this thesis is concerned
                        with a detailed computational model of basic pattern vision
                        in humans and its modulation by top-down attention. We start
                        by acquiring a complete dataset of five different simple
                        psychophysical experiments, including discriminations of
                        contrast, orientation and spatial frequency of simple pattern
                        stimuli by human observers. This experimental dataset places
                        strict constraints on our model of early pattern vision.
                        The model, however, is eventually able to reproduce the
                        entire dataset while assuming plausible neurobiological
                        components. The model is further applied to existing psychophysical
                        data which demonstrates how top-down attention alters performance
                        in these simple psychophysical discrimination experiments.
                        Our model is able to quantitatively account for all observations
                        by assuming that attention strengthens the non-linear cortical
                        interactions among visual neurons. Together, the two aspects
                        of attention studied in this thesis lead us to consider
                        the essential role of non-linear computations in visual
                        processing. We suggest that visual processing, even at its
                        earliest levels, is best characterized not by linear response
                        functions and spatial convolutions, but rather by non-linearly
                        interacting computational devices. },
note                = { The PostScript version will uncompress to over 300 Mbytes! },
address             = { Pasadena, California },
organization        = { California Institute of Technology },
type                = { bu|td|mod|psy|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti00phd.pdf }
}

@inproceedings{Itti99palm,
author              = { L. Itti },
title               = { A saliency-based search mechanism for overt and covert shifts
                        of visual attention },
month = { Nov },
year                = 1999,
booktitle           = { Workshop on Attention. Reisensburg Castle, Guenzburg, Germany },
type                = { bu|mod }
}

@article{Ernst_etal99,
author              = { T. Ernst and O. Speck and L. Itti and L. Chang },
title               = { Simultaneous correction for interscan patient motion and
                        geometric distortions in echoplanar imaging },
journal             = { Magnetic Resonance in Medicine },
volume              = 42,
number              = 1,
pages               = { 201-5 },
month = { Jul },
year                = 1999,
keywords            = { Algorithms | Artifacts | Brain/anatomy & histology | Computer
                        Simulation | Echo-Planar Imaging/*instrumentation | Human
                        | Image Enhancement/*instrumentation | Image Processing,
                        Computer-Assisted/*instrumentation | Reference Values |
                        Support, Non-U.S. Gov't | Support, U.S. Gov't, P.H.S. |
                        1999/07/10 10:00 },
abstract            = { A method is presented for simultaneous correction of linear
                        geometric distortions and interscan patient motion in echoplanar
                        imaging (EPI). The technique does not require the acquisition
                        of specialized scans other than high-resolution magnetic
                        resonance images. The method is based on a generalized surface-based
                        coregistration algorithm, which accounts for a complete
                        3-dimensional affine transformation, i.e., rotations, translations,
                        scaling, and shearing, between two volumetric image data
                        sets. Any minimally distorted high-resolution scan may serve
                        as a reference data set, to which the EPI data set is matched.
                        The algorithmic accuracy was assessed using simulated data
                        sets with known affine distortions. The deviation of the
                        parameters determined by the coregistration program from
                        the true values typically was 1% or less. Precise alignment
                        of functional and anatomic information will be important
                        for many future clinical applications. },
address             = { Harbor UCLA Research and Education Institute, Torrance,
                        USA. },
type                = { mip|fmri },
file                = { http://iLab.usc.edu/publications/doc/Ernst_etal99.pdf }
}

@inproceedings{Niebur99,
author              = { E. Niebur and C. Koch and L. Itti and P. N. Steinmetz and
                        A. Roy and P. Fitzgerald and K. O. Johnson and S. S. Hsiao },
title               = { Modeling Selective Attention },
pages               = 151,
month = { Jun },
year                = 1999,
editor              = { N. Elsner and U. Eysel },
booktitle           = { From Molecular Neurobiology to Clinical Neuroscience, Proceedings
                        of the 1st Goettingen conference of the German Neuroscience
                        Society },
type                = { bu|mod }
}

@article{Speck_etal99,
author              = { O. Speck and L. Chang and L. Itti and E. Itti and T. Ernst },
title               = { Comparison of static and dynamic MRI techniques for the
                        measurement of regional cerebral blood volume },
journal             = { Magnetic Resonance in Medicine },
volume              = 41,
number              = 6,
pages               = { 1264-8 },
month = { Jun },
year                = 1999,
keywords            = { Brain/*anatomy & histology/blood supply | Cerebrovascular
                        Circulation/*physiology | Comparative Study | Contrast Media
                        | Echo-Planar Imaging/methods | Gadolinium DTPA/diagnostic
                        use | Human | Image Processing, Computer-Assisted/methods
                        | Magnetic Resonance Imaging/*methods | Support, Non-U.S.
                        Gov't | Support, U.S. Gov't, P.H.S. | 2000/06/20 09:00 },
abstract            = { Two different acquisition and processing strategies to determine
                        the regional cerebral blood volume (rCBV) with magnetic
                        resonance imaging (MRI) are compared. The first method is
                        based on the acquisition of the signal time course during
                        a bolus administration of a contrast agent (dynamic method).
                        The second method evaluates signal changes before and after
                        the contrast agent injection (static method), assuming the
                        contrast agent remains primarily intravascular in the brain
                        after the first pass. Both methods were applied to the same
                        data sets, acquired with either echoplanar imaging (EPI,
                        n = 18) or fast low-angle shot (FLASH, n = 28) techniques.
                        A voxel-by-voxel correlation between the static and dynamic
                        method yielded a correlation coefficient of 0.76 +/- 0.06
                        for the EPI and 0.71 +/- 0.10 for the FLASH measurements.
                        The static method was less sensitive and showed higher standard
                        deviations for rCBV than the dynamic method. With the development
                        of truly intravascular contrast agents, the static perfusion
                        MRI method, which can be performed with higher signal-to-noise
                        ratio and higher spatial resolution, may become an alternative
                        to ultra-fast MRI for measuring rCBV. },
address             = { Harbor UCLA Research and Education Institute, Torrance,
                        California, USA. },
type                = { mip|fmri },
file                = { http://iLab.usc.edu/publications/doc/Speck_etal99.pdf }
}

@inproceedings{Itti_Koch99nato,
author              = { L. Itti and C. Koch },
title               = { Target Detection using Saliency-Based Attention },
pages               = { 3.1-3.10 },
month = { Jun },
year                = 1999,
keywords            = { Visual attention | saliency | preattentive | inhibition
                        of return | model | winner-take-all | bottom-up | natural
                        scene },
abstract            = { Most models of visual search, whether involving overt eye
                        movements or covert shifts of attention, are based on the
                        concept of a ``saliency map,'' that is, an explicit two-dimensional
                        map that encodes the saliency or conspicuity of objects
                        in the visual environment. Competition among neurons in
                        this map gives rise to a single winning location that corresponds
                        to the next attended target. Inhibiting this location automatically
                        allows the system to attend to the next most salient location.
                        We describe a detailed computer implementation of such a
                        scheme, focusing on the problem of combining information
                        across modalities, here orientation, intensity and color
                        information, in a purely stimulus-driven manner. We have
                        successfully applied this model to a wide range of target
                        detection tasks, using synthetic and natural stimuli. Performance
                        has however remained difficult to objectively evaluate on
                        natural scenes, because no objective reference was available
                        for comparison. We here present predicted search times for
                        our model on the Search2 database of rural scenes containing
                        a military vehicle. Overall, we found a poor correlation
                        between human and model search times. Further analysis however
                        revealed that in 3/4 of the images, the model appeared to
                        detect the target faster than humans (for comparison, we
                        calibrated the model's arbitrary internal time frame such
                        that no more than 2-4 image locations were visited per second).
                        It hence seems that this model, which had originally been
                        designed not to find small, hidden military vehicles, but
                        rather to find the few most obviously conspicuous objects
                        in an image, performed as an efficient target detector on
                        the Search2 dataset. },
booktitle           = { Proc. RTO/SCI-12 Workshop on Search and Target Acquisition
                        (NATO Unclassified), Utrecht, The Netherlands, RTO-MP-45
                        AC/323(SCI)TP/19 },
type                = { bu|mod|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_Koch99nato.pdf }
}

@article{Itti_etal99nc,
author              = { L. Itti and C. Koch and J. Braun },
title               = { A Quantitative Model Relating Visual Neuronal Activity to
                        Psychophysical Thresholds },
journal             = {Neurocomputing},
number              = { 26-27 },
pages               = { 743-748 },
month = { Jun },
year                = 1999,
keywords            = { early vision | model | divisive inhibition | non-linear
                        interactions | masking },
abstract            = { We investigate how a simple, physiologically motivated three-stage
                        neuronal model can establish a quantitative relationship
                        between activities in small populations of simulated early
                        visual neurons and human psychophysical thresholds. The
                        model consists of: First, a bank of linear filters tuned
                        for orientation and spatial period; second, non-linear interactions
                        between filters; and, third, a statistically efficient decision
                        stage. The model quantitatively reproduces human thresholds
                        for five classical pattern discrimination tasks, using a
                        unique set of automatically determined parameters. The resulting
                        model components are all plausible in terms of putative
                        neuronal correlates. },
type                = { mod|psy },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal99nc.pdf }
}

@inproceedings{Ernst_etal99ismrm,
author              = { T. Ernst and O. Speck and L. Itti and L. Chang },
title               = { Simultaneous Correction for Interscan Patient Motion and
                        Geometric Distortions in Echo Planar Imaging },
pages               = 2208,
month = { May },
year                = 1999,
booktitle           = { Proc. 7th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1999) },
type                = {mip}
}

@inproceedings{Speck_etal99ismrm,
author              = { O. Speck and L. Chang and L. Itti and T. Ernst },
title               = { Comparison of Static and Dynamic MRI Techniques for the
                        Measurment of Regional Cerebral Blood Volume },
pages               = 603,
month = { May },
year                = 1999,
booktitle           = { Proc. 7th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1999) },
type                = {mip}
}

@inproceedings{Chang_etal99ismrm,
author              = { L. Chang and O. Speck and E. Miller and J. Braun and L.
                        Itti and T. Ernst },
title               = { Increased Usage of Brain Reserve Capacity in Patients with
                        HIV },
pages               = 822,
month = { May },
year                = 1999,
booktitle           = { Proc. 7th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1999) },
type                = { mip|med|fmri }
}

@inproceedings{Itti_etal99vrc,
author              = { L. Itti and C. Scheier and B. Khurana and C. Koch },
title               = { A Simple Model of Long-Range Interactions for the Computation
                        of Salience },
month = { May },
year                = 1999,
keywords            = { Bottom-up attention | salience | long-range interactions
                        | visual search },
abstract            = { Combining, into a single saliency map, information from
                        multiple feature maps (each encoding for salience in different
                        feature types such as color, intensity or orientation at
                        different spatial scales) poses a signal-to-noise ratio
                        problem for the detection of salient targets among distractors.
                        For example, while an orientation pop-out would strongly
                        appear in an orientation discontinuity map tuned to the
                        target, localized activity resulting from the contrast between
                        image background and target or distractors alike would also
                        strongly appear in intensity and color contrast maps. This
                        equally strong activity of targets and distractors in the
                        intensity and color channels diminishes the effective salience
                        of the target from the orientation channel. We investigated
                        how competition for salience within each feature type may
                        alleviate this signal-to-noise problem. We implemented a
                        simple model of spatial competition between salient locations
                        in the form of iterative rectified filtering by a two-dimensional
                        ``Difference-of-Gaussians'' filter with narrow excitatory
                        and broad inhibitory widths (2% and 25% of the image width).
                        Based on this model, multiple locations initially eliciting
                        comparable responses (such as in an intensity contrast map
                        with an orientation popout stimulus) suppressed each other,
                        while a location initially standing out (such as in an orientation
                        contrast map with an orientation pop-out stimulus) was greatly
                        enhanced. The competitive process hence increased target-to-distractor
                        salience combined over all channels, both by enhancing locally
                        stronger signals and by suppressing spatially comparable
                        signals. This model has been applied successfully to various
                        visual search tasks, and may provide supportive mechanistic
                        evidence for the results of Scheier et al., in which local
                        versus global masking differentially affects visual search. },
booktitle           = { Proc. 3rd Annual Vision Research Conference, Fort Lauderdale,
                        FL },
type                = { mod|bu },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal99vrc.pdf }
}

@inproceedings{Scheier_etal99vrc,
author              = { C. Scheier and B. Khurana and L. Itti and C. Koch },
title               = { Visual Search Amnesic or Memory Driven? },
month = { May },
year                = 1999,
booktitle           = { Proc. 3rd Annual Vision Research Conference, Fort Lauderdale,
                        FL },
type                = {bu}
}

@inproceedings{Itti_etal99arvo,
author              = { L. Itti and J. Braun and C. Koch },
title               = { Contrast Discrimination can Explain Orientation Discrimination },
volume              = 40,
number              = 4,
pages               = 3016,
month = { Mar },
year                = 1999,
abstract            = { Purpose: Many current early vision models consist of a population
                        of noisy orientation-selective filters, followed by noiseless
                        central decision. It has been argued (Bowne, Vis Res 1990;30:449-61)
                        that all such models, with noise only at the sensory level
                        (filters), cannot explain the differential dependence of
                        contrast and orientation discrimination thresholds on stimulus
                        contrast (Delta_c propto c^-0.4 versus Delta_theta propto
                        c^-0.1, c>0.1). Most current models indeed predict improvement
                        with contrast at the same rate for Delta_c/c and Delta_theta,
                        both resulting from an overall improvement in signal-to-noise
                        ratio with stimulus contrast. One way to reconcile both
                        observations is to assume additional, task-dependent noise
                        at the central decision stage (Bowne, 1990). Here, we argue
                        that this apparent contradiction constitutes further evidence
                        for a certain type of non-linear interactions among filters
                        (``divisive inhibition'', also known as ``Heeger normalization'').
                        [[[FIGURE]]] Results: A model with noiseless decision was
                        able to simultaneously account for both observations (figure)
                        by implementing strong non-linear excitatory and inhibitory
                        interactions between filters tuned to similar orientations.
                        Resulting from the interactions, the orientation tuning
                        bandwidth of the filters broadened by 25% as c increased
                        from 0.01 to 0.99, which partially canceled the improvement
                        of Delta_theta with c, but did not affect Delta_c/c. Conclusion:
                        ad hoc task-dependent central noise is unnecessary provided
                        that filters interact. Far from constituting a weakness
                        of current spatial vision models, the differential contrast
                        dependence of different types of thresholds corroborates
                        the current views as to the nature of interactions between
                        filters. },
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        1999) },
type                = { mod|psy },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal99arvo.pdf }
}

@article{Lee_etal99nn,
author              = { D. K. Lee and L. Itti and C. Koch and J. Braun },
title               = { Attention activates winner-take-all competition among visual
                        filters },
journal             = { Nature Neuroscience },
volume              = 2,
number              = 4,
pages               = { 375-81 },
month = { Apr },
year                = 1999,
keywords            = { Attention/*physiology | Contrast Sensitivity/physiology
                        | Discrimination (Psychology)/*physiology | Human | *Models,
                        Neurological | Neurons/physiology | Pattern Recognition,
                        Visual/physiology | Perceptual Masking | Sensory Thresholds
                        | Space Perception/physiology | Support, U.S. Gov't, Non-P.H.S.
                        | Support, U.S. Gov't, P.H.S. | Visual Cortex/*physiology
                        | Visual Perception/*physiology | 1999/04/16 02:03 },
abstract            = { Shifting attention away from a visual stimulus reduces,
                        but does not abolish, visual discrimination performance.
                        This residual vision with 'poor' attention can be compared
                        to normal vision with 'full' attention to reveal how attention
                        alters visual perception. We report large differences between
                        residual and normal visual thresholds for discriminating
                        the orientation or spatial frequency of simple patterns,
                        and smaller differences for discriminating contrast. A computational
                        model, in which attention activates a winner-take-all competition
                        among overlapping visual filters, quantitatively accounts
                        for all observations. Our model predicts that the effects
                        of attention on visual cortical neurons include increased
                        contrast gain as well as sharper tuning to orientation and
                        spatial frequency. },
address             = { Computation and Neural Systems, California Institute of
                        Technology, Pasadena 91125, USA. },
type                = { mod|td|psy },
file                = { http://iLab.usc.edu/publications/doc/Lee_etal99nn.pdf }
}

@article{Ernst_etal99,
author              = { T. Ernst and L. Chang and L. Itti and O. Speck },
title               = { Correlation of regional cerebral blood flow from perfusion
                        MRI and spect in normal subjects },
journal             = { Magnetic Resonance Imaging },
volume              = 17,
number              = 3,
pages               = { 349-54 },
month = { Apr },
year                = 1999,
keywords            = { Adult | Aged | Aged, 80 and over | Blood Flow Velocity/physiology
                        | Brain/*blood supply | Female | Human | Image Enhancement
                        | Image Processing, Computer-Assisted | *Magnetic Resonance
                        Imaging | Male | Middle Age | Reference Values | Regional
                        Blood Flow/physiology | Support, Non-U.S. Gov't | Support,
                        U.S. Gov't, P.H.S. | *Tomography, Emission-Computed, Single-Photon
                        | 1999/04/09 02:03 },
abstract            = { The objective of this study was to determine the relationship
                        in regional cerebral blood flow (rCBF) as measured with
                        perfusion magnetic resonance imaging (pMRI) and single photon
                        emission computer tomography (SPECT). rCBF was determined
                        in 26 healthy subjects with pMRI and SPECT. After co-registration
                        of pMRI with SPECT, rCBF was determined in 10 brain regions
                        relative to the whole slice value. pMRI was evaluated with
                        and without elimination of large vessels. rCBF from pMRI
                        correlates significantly with rCBF from SPECT (r = 0.69
                        with and r = 0.59 without elimination of large vessels;
                        p < 0.0001 for both). Elimination of large vessels reduced
                        the interindividual variance of the pMRI measurements in
                        most regions. rCBF from pMRI shows good correlation with
                        rCBF from SPECT. Because pMRI is sensitive to flow in large
                        vessels while SPECT is not, elimination of large vessels
                        in pMRI reduces the interindividual variability of pMRI
                        and improves the-correlation between the two methods. pMRI
                        is a reliable noninvasive method for rCBF measurements. },
address             = { Department of Radiology, Harbor UCLA Medical Center, Torrance,
                        CA 90502, USA. ernst@afp76.humc.edu },
type                = { med|fmri|mip }
}

@incollection{Itti_etal99nips,
author              = { L. Itti and J. Braun and D. K. Lee and C. Koch },
title               = { Attentional Modulation of Human Pattern Discrimination Psychophysics
                        Reproduced by a Quantitative Model },
pages               = { 789-795 },
month = { Aug },
year                = 1999,
abstract            = { We previously proposed a quantitative model of early visual
                        processing in primates, based on non-linearly interacting
                        visual filters and statistically efficient decision. We
                        now use this model to interpret the observed modulation
                        of a range of human psychophysical thresholds with and without
                        focal visual attention. Our model -- calibrated by an automatic
                        fitting procedure -- simultaneously reproduces thresholds
                        for four classical pattern discrimination tasks, performed
                        while attention was engaged by another concurrent task.
                        Our model then predicts that the seemingly complex improvements
                        of certain thresholds, which we observed when attention
                        was fully available for the discrimination tasks, can best
                        be explained by a strengthening of competition among early
                        visual filters. },
editor              = { M. S. Kearns and S. A. Solla and D. A. Cohn },
publisher           = { MIT Press },
address             = { Cambridge, MA },
booktitle           = { Advances in Neural Information Processing Systems, Vol.
                        11 },
type                = { mod|td|psy },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal99nips.pdf },
url                 = { http://klab.caltech.edu/~itti/topdown/98_NIPS/ }
}

@inproceedings{Itti_etal99eilat,
author              = { L. Itti and J. Braun and D. K. Lee and C. Koch },
title               = { Attentional Modulation of Human Pattern Discrimination Psychophysics
                        Reproduced by a Quantitative Model },
pages               = 41,
month = { Mar },
year                = 1999,
booktitle           = { Proc. Joint Symposium on Frontiers in Computational Neuroscience,
                        Eilat, Israel },
type                = { td|mod }
}

@inproceedings{Itti_Koch99spie,
author              = { L. Itti and C. Koch },
title               = { A Comparison of Feature Combination Strategies for Saliency-Based
                        Visual Attention Systems },
volume              = 3644,
pages               = { 473-82 },
month = { Jan },
year                = 1999,
abstract            = { Bottom-up or saliency-based visual attention allows primates
                        to detect non-specific conspicuous targets in cluttered
                        scenes. A classical metaphor, derived from electrophysiological
                        and psychophysical studies, describes attention as a rapidly
                        shiftable 'spotlight'. The model described here reproduces
                        the attentional scanpaths of this spotlight: Simple multi-scale
                        'feature maps' detect local spatial discontinuities in intensity,
                        color, orientation or optical flow, and are combined into
                        a unique 'master' or 'saliency' map. the saliency map is
                        sequentially scanned, in order of decreasing saliency, by
                        the focus of attention. We study the problem of combining
                        feature maps, from different visual modalities and with
                        unrelated dynamic ranges, into a unique saliency map. Four
                        combination strategies are compared using three databases
                        of natural color images: (1) Simple normalized summation,
                        (2) linear combination with learned weights, (3) global
                        non-linear normalization followed by summation, and (4)
                        local non-linear competition between salient locations.
                        Performance was measured as the number of false detections
                        before the most salient target was found. Strategy (1) always
                        yielded poorest performance and (2) best performance, with
                        a 3- to 8-fold improvement in time to find a salient target.
                        However, (2) yielded specialized systems with poor generations.
                        Interestingly, strategy (4) and its simplified, computationally
                        efficient approximation (3) yielded significantly better
                        performance than (1), with up to 4-fold improvement, while
                        preserving generality. },
booktitle           = { Proc. SPIE Human Vision and Electronic Imaging IV (HVEI'99),
                        San Jose, CA },
type                = { mod|bu|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_Koch99spie.pdf }
}

@article{Itti_etal98pami,
author              = { L. Itti and C. Koch and E. Niebur },
title               = { A Model of Saliency-Based Visual Attention for Rapid Scene
                        Analysis },
journal             = { IEEE Transactions on Pattern Analysis and Machine Intelligence },
volume              = 20,
number              = 11,
pages               = { 1254-1259 },
month = { Nov },
year                = 1998,
keywords            = { Visual attention | target detection | saliency | image understanding },
abstract            = { A trainable visual attention system, inspired by the behavior
                        and the neuronal architecture of the early primate visual
                        system, is presented. Multiscale image features are combined
                        into a single topographical saliency map. A dynamical neural
                        network then selects attended locations in order of decreasing
                        saliency. The system breaks down the complex problem of
                        scene understanding by rapidly selecting, in a computationally
                        efficient manner, conspicuous locations to be analyzed in
                        detail. },
type                = { mod|bu|cv },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal98pami.pdf },
url                 = { http://klab.caltech.edu/~itti/attention/publications/98_PAMI/ }
}

@inproceedings{Braun_etal98sfn,
author              = { J. Braun and D. K. Lee and L. Itti and C. Koch },
title               = { Parallels Between Psychophysical and Neuronal Models of
                        Orientation Tuning },
pages               = 767,
month = { Nov },
year                = 1998,
booktitle           = { Proc.Society for Neuroscience Annual Meeting (SFN'98) },
type                = { mod|psy }
}

@incollection{Itti_etal98nips,
author              = { L. Itti and J. Braun and D. K. Lee and C. Koch },
title               = { A Model of Early Visual Processing },
pages               = { 173-179 },
month = { Aug },
year                = 1998,
abstract            = { We propose a model for early visual processing in primates.
                        The model consists of a population of linear spatial filters
                        which interact through non-linear excitatory and inhibitory
                        pooling. Statistical estimation theory is then used to derive
                        human psychophysical thresholds from the responses of the
                        entire population of units. The model is able to reproduce
                        human thresholds for contrast and orientation discrimination
                        tasks, and to predict contrast thresholds in the presence
                        of masks of varying orientation and spatial frequency. },
editor              = { M. I. Jordan and M. J. Kearns and S. A. Solla },
publisher           = { MIT Press },
address             = { Cambridge, MA },
booktitle           = { Advances in Neural Information Processing Systems, Vol.
                        10 },
type                = { mod|psy },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal98nips.pdf },
url                 = { http://klab.caltech.edu/~itti/topdown/97_NIPS/ }
}

@patent{Ernst_etal98pat,
author              = { T. Ernst and L. Chang and L. Itti },
title               = { An Automated Scanning Apparatus for Tomographic Images },
year                = 1998,
keywords            = { automated | scan acquisition | scanner | human | medical
                        | image processing },
abstract            = { The invention describes an apparatus and computer algorithm
                        which allows for fast and accurate acquisition of tomographic
                        scans, always in the same frame of reference irrespectively
                        of patient positioning, using conventional scanners. The
                        invention not only significantly reduces total scan time
                        but also ensures reproducibility of the scanning process,
                        which is useful for follow-up studies. },
note                = { U.S. Patent number 09/272,436. },
organization        = { Harbor-UCLA Research and Education Institute, Torrance,
                        CA, USA },
type                = {mip}
}

@patent{Itti_etal98copy,
author              = { L. Itti and L. Chang and T. Ernst },
title               = { Coregistration for Neuroimaging Systems (C.N.S.) },
year                = 1998,
keywords            = { Medical Imaging | Image Processing | MRI | SPECT | Coregistration
                        | Software },
abstract            = { C.N.S. is a medical image processing software suite consisting
                        of 300 processing modules and over 250 networks of such
                        modules, developed at Harbor-UCLA Medical Center with Drs.~Chang
                        and Ernst, as well as through a number of collaborations.
                        The software includes, among others, custom automated algorithms
                        for skull stripping, surface-based coregistration, segmentation
                        of CSF, correction for partial volume effects in SPECT/PET/pMRI,
                        coregistration of MRS to MRI allowing accurate MRS localization
                        on follow-up scans, MRI morphometry and drawing of regions
                        of interest, extraction of white-matter lesions, correction
                        for MRI intensity decay with surface coils, correction for
                        geometric distortions and patient motion in EPI-fMRI, sparse
                        fusion of fMRI time series across sessions, computation
                        of fMRI activation, computation of blood flow in Gd-pMRI,
                        elimination of large vessels in pMRI, computation of diffusion
                        tensor in dMRI, 3D surface mesh reconstruction and optimization,
                        and various 2D and 3D visualization tools, classical image
                        processing tools and image conversion tools. <P> The system
                        can be simultaneously built and executed by an unrestricted
                        number of users on various hardware platforms, can automatically
                        generate restricted distributions and updates from the master
                        system, and automatically generates LaTeX and HTML manuals
                        from the online help pages. Copyright by Harbor-UCLA Research
                        and Education Institute. <P> In addition to being a key
                        component of our research at the Dept. of Neurology, Harbor-UCLA
                        Medical Center, our system or parts of it is being used
                        at The National Institutes of Health, the University of
                        California, San Francisco (UCSF), the University of California,
                        San Diego (UCSD), the University of California, Los Angeles,
                        Veterans Affairs Medical Center (UCLA-VAMC), Harbor-UCLA
                        Medical Center, Dept. of Nuclear Medicine, and the Weill
                        Medical College of Cornell University. },
address             = { Harbor-UCLA REI - 1124 W. Carson St. - Torrance, CA 90502 },
organization        = { Harbor-UCLA Research and Education Institute },
type                = { mip|fmri },
url                 = { http://iLab.usc.edu/cns/ }
}

@inproceedings{Itti_etal98ismrm1,
author              = { L. Itti and T. Ernst and J. Braun and L. Chang },
title               = { Fusion of fMRI Time-Series Across Sessions },
pages               = 1489,
month = { Apr },
year                = 1998,
booktitle           = { Proc. 6th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1999), Sydney, Australia },
type                = { mip|fmri },
file                = { http://ilab.usc.edu/publications/doc/Itti_etal98ismrm1.pdf }
}

@inproceedings{Itti_etal98ismrm2,
author              = { L. Itti and L. Chang and T. Ernst },
title               = { Manual and Automatic Extraction of White-Matter Lesions
                        in FLAIR Images },
pages               = 2073,
month = { Apr },
year                = 1998,
booktitle           = { Proc. 6th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1999), Sydney, Australia },
type                = { mip|fmri },
file                = { http://ilab.usc.edu/publications/doc/Itti_etal98ismrm2.pdf }
}

@inproceedings{Itti_etal98arvo,
author              = { L. Itti and C. Koch and J. Braun },
title               = { A Model for the Attentional Modulation of Spatial Vision,
                        Continued },
volume              = 39,
number              = 4,
pages               = 2934,
month = { Mar },
year                = 1998,
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        1998) },
type                = { td|mod|psy },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal98arvo.pdf }
}

@inproceedings{Lee_etal98arvo,
author              = { D. K. Lee and C. Koch and L. Itti and J. Braun },
title               = { Attentional Modulation of Contrast Masking, Continued },
volume              = 39,
number              = 4,
pages               = 2938,
month = { Mar },
year                = 1998,
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        1998) },
type                = {psy}
}

@inproceedings{Braun_etal97sfn,
author              = { J. Braun and T. Ernst and R. Wang and L. Chang and L. Itti
                        and P. Ledden and C. Koch },
title               = { A fMRI Study of Cortical Activity During Visual Segmentation },
pages               = { 755.12 },
month = { Oct },
year                = 1997,
booktitle           = { Proc. Society for Neuroscience Annual Meeting (SFN'97) },
type                = {fmri}
}

@article{Itti_etal97hbm2,
author              = { L. Itti and L. Chang and T. Ernst and F. Mishkin },
title               = { Improved 3D correction for partial volume effects in brain
                        SPECT },
journal             = { Human Brain Mapping },
volume              = 5,
number              = 5,
pages               = { 379-388 },
year                = 1997,
keywords            = { partial volume effects | MRI | SPECT | brain atrophy | image
                        processing },
abstract            = { An improved method for correction of partial volume effects
                        (PVE) in brain SPECT is proposed. It is fully three-dimensional,
                        does not require particular patient positioning, and works
                        with scans only partially covering the brain. The location
                        of functionally inactive brain regions (primarily cerebrospinal
                        fluid) is extracted from high-resolution MRI. An automatic
                        3D registration algorithm then determines the geometric
                        transformation between MRI and SPECT. Correction consists
                        of: 1) counting the volumetric active/inactive ratio in
                        each volume element of the functional scan using the measured
                        SPECT point spread function; 2) correcting the functional
                        measures according to these ratios; 3) fusing functional
                        and anatomical information at the resolution of MRI. Quantitative
                        validation was performed using a phantom containing a test
                        region in which multiple parallel acrylic plates thinner
                        than SPECT resolution created high PVE, as well. as a large
                        reference region not suffering from PVE. Reference activity
                        was recovered in the test region with an accuracy of 1-3
                        percent. The method was applied to clinical images demonstrating
                        a combination of hypoperfusion and cortical atrophy. The
                        composite anatomical-functional corrected images, in which
                        the main sulci are visible, yield better differentiation
                        between decreased function and focal atrophy. },
type                = {mip}
}

@inproceedings{Itti_etal97ismrm,
author              = { L. Itti and L. Chang and D. Osborn and T. Ernst },
title               = { Automated Extraction of White Matter Lesions in FLAIR Images },
pages               = 418,
month = { Apr },
year                = 1997,
booktitle           = { Proc. 5th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1997), Vancouver,
                        Canada },
type                = {mip}
}

@inproceedings{Ernst_etal97ismrm,
author              = { T. Ernst and L. Chang and L. Itti },
title               = { Elimination of Large Vessels Improves Reproducibility of
                        Perfusion MRI },
pages               = 1791,
month = { Apr },
year                = 1997,
booktitle           = { Proc. 5th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1997), Vancouver,
                        Canada },
type                = {mip}
}

@inproceedings{Itti_etal97arvo,
author              = { L. Itti and C. Koch and J. Braun },
title               = { A Model for the Attentional Modulation of Spatial Vision },
volume              = 38,
number              = 4,
pages               = 5461,
month = { Mar },
year                = 1997,
abstract            = { Purpose: We present a computational model of interactions
                        between visual spatial filters in humans. The model accounts
                        for a range of visual spatial thresholds and their modulation
                        by attention (Wen et al., ARVO'97). Methods: The model assumes
                        that each visual location is analyzed by a set of spatial
                        filters tuned for different spatial frequencies $(lambda)$
                        and orientations $(theta)$. Pairs of filters in quadrature
                        phase produce an energy response, $E_{lambda,theta}$, which
                        is normalized by the responses $E_{lambda',theta'}$ of a
                        subset of filters, centered around $(lambda,theta)$ and
                        weighted by coefficients $w_{lambda,theta}(lambda',theta')$,
                        yielding the pooled energy: $${cal E}_{lambda,theta} = {{E_{lambda,theta}^{gamma}}over
                        {sigma_{lambda}^{delta}+sum_{lambda',theta'} w_{lambda,theta}(lambda',theta')
                        E_{lambda',theta'}^{delta}}} qquad (gamma approx 2; delta
                        approx 1.5, without attention)$$ Psychophysical performance
                        is derived by assuming that each filter exhibits constant
                        background noise plus Poisson noise and by selecting the
                        most sensitive filter for each task (ROC analysis). Results:
                        The model is similar to models of contrast gain control
                        in cat simple cells (Heeger, Vis. Neurosci. 9:181-97, 1992)
                        and produces, without additional assumptions, the ``dip-shaped''
                        non-linearity characteristic of human threshold vision (Wilson
                        et al., Vis. Res. 23:873--82, 1983). Our model differs from
                        others in that only a relatively narrow normalization pool
                        (halfwidth of weight function $approx 1octave$ and $approx
                        15^circ$) accounts for human vision. The model successfully
                        reproduces human contrast, contrast increment, and orientation
                        discrimination thresholds, as well as threshold elevation
                        by contrast masking (Wen et al., ARVO'96&'97). Increasing
                        both exponents $gamma$ and $delta$ accounts for the effect
                        of attention. Conclusion: The results suggest that attention
                        increases the gain and sharpens the tuning of visual spatial
                        filters, by strengthening normalizing interactions between
                        such filters. },
booktitle           = { Investigative Ophthalmology and Visual Science (Proc. ARVO
                        1997) },
type                = { td|mod|psy }
}

@article{Kaufer_etal97,
author              = { D. I. Kaufer and B. L. Miller and L. Itti and L. A. Fairbanks
                        and J. Li and J. Fishman and J. Kushi and J. L. Cummings },
title               = { Midline cerebral morphometry distinguishes frontotemporal
                        dementia and Alzheimer's disease },
journal             = {Neurology},
volume              = 48,
number              = 4,
pages               = { 978-85 },
month = { Apr },
year                = 1997,
keywords            = { Aged | Aged, 80 and over | Algorithms | Alzheimer Disease/*diagnosis/psychology
                        | Brain/*pathology | Dementia/*diagnosis/psychology | Diagnosis,
                        Differential | Discriminant Analysis | Female | *Frontal
                        Lobe | Human | Magnetic Resonance Imaging | Male | Middle
                        Age | Psychiatric Status Rating Scales | Reference Values
                        | Support, Non-U.S. Gov't | Support, U.S. Gov't, Non-P.H.S.
                        | Support, U.S. Gov't, P.H.S. | *Temporal Lobe | 1997/04/01
                        00:00 },
abstract            = { We investigated and contrasted midline cerebral structures
                        in frontotemporal dementia (FTD) and Alzheimer's disease
                        (AD). FTD and AD may be difficult to distinguish clinically.
                        FTD typically affects frontal and anterior temporal regions,
                        whereas AD tends to involve more posterior temporal and
                        parietal areas. We hypothesized that disease-specific cerebral
                        alterations would be differentially reflected in corresponding
                        regions of the corpus callosum (CC), pericallosal CSF space
                        (PCS), or their ratio (CC:PCS). Regions-of-interest (ROIs)
                        from midsagittal MRIs in 17 AD, 16 FTD, and 12 elderly control
                        (EC) subjects were analyzed. ROIs were divided into four
                        regions using an anatomic landmark-based computer algorithm
                        and were adjusted for head size variation. FTD subjects
                        had a much smaller anterior CC region and significantly
                        larger PCS area, particularly in anterior regions. AD and
                        EC subjects did not differ significantly in any total or
                        regional ROI measure. Total and anterior CC:PCS ratios were
                        markedly lower in FTD patients. Across groups, total CC:PCS
                        correlated significantly with midsagittal cerebral area
                        and was similarly associated with Mini-Mental State Examination
                        score. Anterior CC (AD) and PCS (FTD) regions exhibited
                        disease-specific relationships to these variables. A discriminant
                        model using two ROI variables correctly classified 91% of
                        AD and FTD patients, comparing favorably with blind clinical
                        MRI diagnostic ratings. Midline cerebral structural alterations
                        reflect differential patterns of cerebral degeneration in
                        AD and FTD, yielding morphometric indices that may facilitate
                        the study of brain-behavior relationships and differential
                        diagnosis of dementia. },
address             = { Department of Psychiatry, University of Pittsburgh School
                        of Medicine, PA, USA. },
type                = {med}
}

@inproceedings{Lee_etal97cns,
author              = { D. K. Lee and L. Itti and C. Koch and J. Braun },
title               = { Attentional Modulation of Spatial Vision },
pages               = 125,
month = { Mar },
year                = 1997,
booktitle           = { Proc. Cognitive Neuroscience Society, 4th Annual Meeting
                        (CNS'97) },
type                = {psy}
}

@article{Itti_etal97hbm1,
author              = { L. Itti and L. Chang and J. F. Mangin and J. Darcourt and
                        T. Ernst },
title               = { Robust multimodality registration for brain mapping },
journal             = { Human Brain Mapping },
volume              = 5,
number              = 1,
pages               = { 3-17 },
year                = 1997,
keywords            = { multimodality registration | neuroimaging | brain | chamfer
                        matching | brain surface | image processing },
abstract            = { We present a robust intrasubject registration method for
                        the synergistic use of multiple neuroimaging modalities,
                        with applications to magnetic resonance imaging (MRI), functional
                        MRI, perfusion MRI, MR spectroscopy, and single-photon emission
                        computed tomography (SPECT). This method allows user-friendly
                        processing of difficult examinations (low spatial resolution,
                        advanced pathology, motion during acquisition, and large
                        areas of focal activation). Registration of three-dimensional
                        (3D) brain scans is initially estimated by first-order moment
                        matching, followed by iterative anisotrophic chamfer matching
                        of brain surfaces. Automatic brain surface extraction is
                        performed in all imaging modalities. A new generalized distance
                        definition and new specific methodologies allow registration
                        of scans that cover only a limited range of brain surface.
                        A new semiautomated supervision scheme allows fast and intuitive
                        corrections of possible false automatic registration results.
                        The accuracy of the MRI/SPECT anatomical-functional correspondence
                        obtained was evaluated using simulations and two difficult
                        clinical populations (tumors and degenerative brain disorders).
                        The average discrimination capability of SPECT (12.4 mm
                        in-plane resolution, 20 mm slice thickness) was found to
                        be better than 5 mm after registration with MRI (5 mm slice
                        thickness). Registration accuracy was always better than
                        imaging resolution. Complete 3D MRI and SPECT registration
                        time ranged between 6-11 min, in which surface matching
                        represented 2-3 min. No registration failure occurred. In
                        conclusion, the application of several new image processing
                        techniques allowed efficient and robust registration. },
type                = {mip}
}

@article{Craig_etal96,
author              = { A. H. Craig and J. L. Cummings and L. Fairbanks and L. Itti
                        and B. L. Miller and J. Li and I. Mena },
title               = { Cerebral blood flow correlates of apathy in Alzheimer disease },
journal             = { Archives of Neurology },
volume              = 53,
number              = 11,
pages               = { 1116-20 },
month = { Nov },
year                = 1996,
keywords            = { Aged | Aged, 80 and over | Alzheimer Disease/*physiopathology/psychology/radionuclide
                        imaging | Cerebrovascular Circulation/*physiology | Female
                        | Frontal Lobe/physiopathology | Human | Male | Middle Age
                        | Psychiatric Status Rating Scales | Support, U.S. Gov't,
                        Non-P.H.S. | Support, U.S. Gov't, P.H.S. | Temporal Lobe/physiopathology
                        | Tomography, Emission-Computed, Single-Photon | 1996/11/01
                        00:00 },
abstract            = { BACKGROUND: Apathy is a pervasive noncognitive neuropsychiatric
                        disturbance in Alzheimer disease, which causes significant
                        caregiver distress. The neuroanatomical substrate of apathy
                        is not well understood. OBJECTIVE: To study the relationship
                        between regional cerebral blood flow and the presence and
                        severity of the personality disturbance, apathy, in individuals
                        with Alzheimer disease. DESIGN: Analysis of the relationship
                        between regional cerebral blood flow as measured by single
                        photon emission computed tomography and severity of apathy
                        as measured by the Neuropsychiatric Inventory using an analysis
                        of variance design. We examined regional cerebral perfusion
                        alterations as measured by xenon 133Xecalibrated technetium
                        Tc 99m hexamethyl-propyleneamine-oxime single photon emission
                        computed tomography in relation to the presence and severity
                        of apathy. SETTING: The neurology clinics of the University
                        of California, Los Angeles, UCLA School of Medicine, and
                        Harbor-UCLA Medical Center. PARTICIPANTS: Thirty-one community-dwelling
                        patients fulfilling National Institute of Neurological and
                        Communicative Disorders and Stroke-Alzheimer's Disease and
                        Related Disorders Association diagnostic criteria for probable
                        Alzheimer disease who had a single photon computed tomographic
                        scan performed within 3 months of administration of the
                        Neuropsychiatric Inventory. RESULTS: The presence of apathy
                        was associated with more severe prefrontal and anterior
                        temporal dysfunction. These regional cerebral perfusion
                        relationships with apathy were independent of cognitive
                        decline except in the dorsolateral prefrontal cortex. CONCLUSIONS:
                        These results demonstrate the association of apathetic syndromes
                        with prefrontal and anterior temporal regional brain dysfunction
                        and are consistent with similar findings previously reported
                        in other disorders. },
address             = { Department of Neurology, University of California, Los Angeles,
                        USA. },
type                = {med}
}

@inproceedings{Itti_etal96sfn,
author              = { L. Itti and E. Niebur and J. Braun and C. Koch },
title               = { A Trainable Model of Visual Attention },
pages               = 270,
month = { Nov },
year                = 1996,
abstract            = { We present a model of bottom-up selective visual attention,
                        developed in accordance with the known physiology of the
                        visual system of macaque monkeys and humans. The model comprises
                        two interacting stages, the first being a fast and parallel
                        pre-attentive extraction of visual features (orientation,
                        intensity and color, at several spatial scales), and the
                        second a slow and sequential focal attention shifting mechanism
                        (Winner-Take-All neural network for the selection of the
                        most conspicuous image location, and inhibition-of-return
                        mechanism to generate attentional shifts). The link between
                        the two stages is a ``saliency map'', which topographically
                        encodes for the local conspicuity in the visual scene, and
                        controls where the focus of attention is currently deployed
                        [Koch and Ullman, Human Neurobiol. 1985;4:219-227]. Supervized
                        learning can be introduced to bias the relative weights
                        of the features in the construction of the saliency map
                        and achieve some degree of specialization towards target
                        detection tasks. Despite its simplicity, this model has
                        demonstrated interesting performances in reproducing human
                        stimulus-driven task independent attention. Results with
                        the model are comparable to humans' on simple psychophysical
                        tasks (e.g. A. Treisman's pop-out and conjunctive search).
                        Good performance was also obtained in the detection of salient
                        targets in natural color images, despite high noise, large
                        variations in color and illumination, shadows, reflections
                        and strong textures, which are reputed problematic for artificial
                        vision systems (an interactive demonstration may be found
                        at http://www.klab.caltech.edu/~itti/). },
booktitle           = { Proc. Society for Neuroscience Annual Meeting (SFN'96) },
type                = { bu|mod },
file                = { http://iLab.usc.edu/publications/doc/Itti_etal96sfn.pdf }
}

@inproceedings{Braun_etal96to,
author              = { J. Braun and J. J. Wen and L. Itti and C. Koch },
title               = { Concurrent-Task Studies of Attention },
year                = 1996,
booktitle           = { Proc. Canadian Institute for Advanced Research, Artificial
                        Intelligence and Robotics Program, Workshop on Visual Attention:
                        Focus on Modeling, Toronto, Canada },
type                = {psy}
}

@inproceedings{Niebur_etal96to,
author              = { E. Niebur and L. Itti and C. Koch },
title               = { A Neural Model for the ''Where'' Pathway },
year                = 1996,
booktitle           = { Proc. Canadian Institute for Advanced Research, Artificial
                        Intelligence and Robotics Program, Workshop on Visual Attention:
                        Focus on Modeling, Toronto, Canada },
type                = { bu|mod }
}

@inproceedings{Goldberg_etal96,
author              = { A. Goldberg and L. Chang and L. Itti and I. Mena and B.
                        L. Miller },
title               = { Visual Agnosia in Alzheimer Disease },
volume              = 46,
pages               = {A358},
year                = 1996,
booktitle           = { Neurology Annual Meeting },
type                = { med|mip }
}

@inproceedings{Kaufer_etal96,
author              = { D. Kaufer and L. Itti and B. Miller and L. Fairbanks and
                        J. Li and J. Fishman and J. Cummings },
title               = { Midline Cerebral Morphometry Discriminates Frontotemporal
                        Dementia and Alzheimer's Disease },
volume              = 46,
pages               = 2061,
year                = 1996,
booktitle           = { Neurology Annual Meeting },
type                = { med|mip }
}

@article{Benson_etal96,
author              = { D. F. Benson and A. Djenderedjian and B. L. Miller and N.
                        A. Pachana and L. Chang and L. Itti and I. Mena },
title               = { Neural basis of confabulation },
journal             = {Neurology},
volume              = 46,
number              = 5,
pages               = { 1239-43 },
month = { May },
year                = 1996,
keywords            = { Adult | Alcohol Amnestic Disorder/*physiopathology/psychology
                        | Case Report | Cerebrovascular Circulation | Cognition
                        Disorders/etiology/physiopathology | Diencephalon/physiopathology/radionuclide
                        imaging | Female | Frontal Lobe/physiopathology/radionuclide
                        imaging | Human | Learning Disorders | Neuropsychological
                        Tests | Organotechnetium Compounds/diagnostic use | Oximes/diagnostic
                        use | Regional Blood Flow | Tomography, Emission-Computed,
                        Single-Photon | 1996/05/01 00:00 },
abstract            = { We present a case of acute alcohol-induced Korsakoff amnesia.
                        A severe amnestic-confabulatory syndrome characterized the
                        early clinical status. The initial neuropsychological tests
                        demonstrated severe learning deficits plus impaired performance
                        on many, but not all, tests of frontal lobe function. Single-photon
                        emission CT (SPECT) at this stage showed hypoperfusion in
                        the orbital and medical frontal regions and the medial diencephalic
                        area. Four months later, the patient's amnesia remained
                        but there was no confabulation. Repeat neuropsychological
                        tests confirmed an ongoing severe amnesia, but performance
                        on the frontal lobe tests now was normal. Repeat SPECT showed
                        a return to normal perfusion in the frontal brain areas
                        but little improvement in the medial diencephalic region.
                        These findings along with data from the clinical literature
                        suggest that confabulation results from dysfunction of orbital
                        and a medial frontal cortex. },
address             = { Department of Neurology, UCLA School of Medicine, USA. },
type                = {med}
}

@inproceedings{Itti_etal96ismrm,
author              = { L. Itti and L. Chang and T. Ernst },
title               = { Robust Multimodality Registration for Neuroimaging },
pages               = 35,
month = { Apr },
year                = 1996,
booktitle           = { Proc. 4th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1996), New York, NY },
type                = {mip}
}

@inproceedings{Ernst_etal96ismrm,
author              = { T. Ernst and L. Chang and L. Itti },
title               = { Correlation of Perfusion MRI and SPECT in Normal Subjects },
pages               = 1304,
month = { Apr },
year                = 1996,
booktitle           = { Proc. 4th Annual Meeting of the International Society for
                        Magnetic Resonance in Medicine (ISMRM'1996), New York, NY },
type                = { mip|med }
}

@article{Miller_etal95,
author              = { B. L. Miller and L. Itti and J. Li and A. L. Darby and R.
                        Booth and L. Chang and I. Mena },
title               = { Atrophy-Corrected Cerebral Blood Flow in Fronto-Temporal
                        Dementia },
journal             = { Facts and Research in Gerontology },
number              = {S},
pages               = { 93-103 },
year                = 1995,
type                = { mip|med }
}

@inproceedings{Benson_etal95,
author              = { D. F. Benson and B. L. Miller and L. Chang and N. Pahana
                        and I. Mena and A. Djenderedjian and L. Itti },
title               = { The Anatomical Substrate of Confabulation },
volume              = 45,
pages               = {A389},
year                = 1995,
booktitle           = { Neurology Annual Meeting },
type                = { med|mip }
}

@inproceedings{Itti_etal95hbm,
author              = { L. Itti and L. Chang and T. Ernst and B. L. Miller and I.
                        Mena },
title               = { High-Resolution Atrophy Correction in Brain SPECT },
volume              = {S1},
pages               = 132,
month = { Jun },
year                = 1995,
booktitle           = { Human Brain Mapping (Proc. First International Conference
                        on Functional Mapping of the Human Brain, Paris, France },
type                = {mip}
}

@inproceedings{Itti_etal95nid,
author              = { L. Itti and L. Chang and T. Ernst and B. L. Miller and I.
                        Mena },
title               = { High-Resolution Atrophy Correction in Brain SPECT },
month = { Mar },
year                = 1995,
booktitle           = { Proc. Neuroimaging in Dementia, Nice, France },
type                = {mip}
}

@inproceedings{Goldberg_etal95nid,
author              = { A. Goldberg and L. Chang and L. Itti and B. L. Miller and
                        I. Mena },
title               = { Visual Agnosia in Alzheimer Disease },
month = { Mar },
year                = 1995,
booktitle           = { Proc. Neuroimaging in Dementia, Nice, France },
type                = {med}
}

@inproceedings{Itti_etal95nih,
author              = { L. Itti and L. Chang and P. Morales and B. L. Miller },
title               = { New computer methods in neurological image processing },
month = { Mar },
year                = 1995,
booktitle           = { Proc. Annual NIH-GCRC Meeting, San Diego, CA },
type                = {mip}
}

@inproceedings{Chang_etal95nih,
author              = { L. Chang and P. Lutchmansingh and R. Poland and B. Palmer
                        and K. Boone and R. Melchor and T. Ernst and L. Itti and
                        I. Mena },
title               = { Cerebral Blood Flow, Biochemical Changes, Cognitive Deficits
                        and Sleep Apnea in Myotonic Dystrophy },
month = { Mar },
year                = 1995,
booktitle           = { Proc. Annual NIH-GCRC Meeting, San Diego, CA },
type                = {med}
}

@inproceedings{Anderson_etal94ana,
author              = { P. G. Anderson and N. Ortego and L. Chang and B. L. Miller
                        and R. Melchor and L. Itti and E. Singer and H. Myers and
                        P. Satz and I. Mena and B. Palmer },
title               = { Co-registration of Single Photon Emission Computed Tomography
                        and Magnetic Resonance Imaging in HIV-1-associated Dementia
                        Complex },
month = { Oct },
year                = 1994,
booktitle           = { Proc. 119th Annual Meeting of the American Neurological
                        Association, San Francisco, CA },
type                = { mip|med }
}

@mastersthesis{Itti94ms,
author              = { L. Itti },
title               = { Mise en Correspondance d'Atlas et d'Images Anatomiques 3D
                        pour la Cartographie Fonctionnelle Cerebrale },
month = { Jun },
year                = 1994,
keywords            = { Computerized brain atlas },
abstract            = { Les etudes actuelles visant a etablir une cartographie fonctionnelle
                        du cerveau humain necessitent la comparaison d'informations
                        fonctionnelles (tomographie d'emission de positons, magneto-encephalographie...)
                        provenant de plusieurs individus. Cette comparaison repose
                        sur la mise en correspondance prealable des anatomies individuelles
                        (images IRM) avec un atlas. Le but du memoire est dans un
                        premier temps de faire le point sur les methodes relativement
                        frustes actuellement utilisees pour realiser cette mise
                        en correspondance, puis d'envisager de nouvelles approches
                        utilisant les outils performants recemment developpes dans
                        le monde du traitement des images (contours actifs, extraction
                        de lignes de courbure maximale sur des surfaces, topologie
                        discrete, champs de Markov...). Les approches proposees
                        devront inclure la representation des donnees symboliques
                        et (ou) numeriques envisagees pour manipuler l'atlas. },
note                = { [in French] },
organization        = { Ecole Nationale Superieure des Telecommunications, Paris },
type                = {mip}
}

@inproceedings{Darcourt_etal94snm,
author              = { J. Darcourt and L. Itti and L. Chang and J. C. Cauvin and
                        B. L. Miller and I. Mena },
title               = { Tl-201 and Tc-99-MIBI SPECT for Brain Tumor Detection: Comparison
                        using MRI Coregistration },
volume              = 35,
number              = 5,
pages               = { P43-P44 },
month = { Jun },
year                = 1994,
booktitle           = { Journal of Nuclear Medicine (Proc. Annual Meeting of the
                        Society of Nuclear Medicine) },
type                = { mip|med }
}

@inproceedings{Damien_etal92,
author              = { J. Damien and L. Itti and P. Egroizard and R. Itti },
title               = { Left Ventricle Detection in Radionuclide Ventriculography
                        by a Model of Neural Network },
month = { Oct },
year                = 1992,
booktitle           = { Proc. 14th Annual International Conference of the IEEE Engineering
                        in Medicine and Biology Society (IEEE-EMBS), Paris, France },
type                = {mip}
}

@inproceedings{Itti_etal91,
author              = { L. Itti and R. Itti and J. Damien },
title               = { Development of a Micro-Computer Based System for Scintigraphic
                        Image Display and Processing },
month = { Mar },
year                = 1991,
booktitle           = { Proc. 2nd International Symposium on Computer Applications
                        in nuclear Medicine and Cardiac Magnetic Resonance Imaging,
                        Rotterdam, The Netherlands },
type                = {mip}
}

@inproceedings{Itti_Itti90,
author              = { L. Itti and R. Itti },
title               = { Traitement d'Images Radioisotopiques Cardiaques sur Micro-Ordinateur },
month = { Oct },
year                = 1990,
booktitle           = { Proc. SYNBIO Techniques Avancees pour les Sciences de la
                        Vie, Lyon, France },
type                = {mip}
}

@inproceedings{Itti_etal89,
author              = { L. Itti and A. Dougangi and D. Casset-Senon and R. Itti },
title               = { Scintigraphic Display and Processing Software Developed
                        on a Personal Computer },
volume              = 30,
number              = 5,
pages               = 1046,
month = { May },
year                = 1989,
booktitle           = { Journal of Nuclear Medicine (Proc. 36th Annual Meeting of
                        the Society of Nuclear Medicine, Saint Louis, MS) },
type                = {mip}
}

